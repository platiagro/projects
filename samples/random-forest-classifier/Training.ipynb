{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "This is a component that trains a Random Forest Classifier model using [Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html). \n",
    "<br>\n",
    "Scikit-learn is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection and evaluation, and many other utilities.\n",
    "\n",
    "This notebook shows:\n",
    "- how to use SDK to load the dataset and save a model.\n",
    "- how to receive parameters from the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = \"iris\" #@param {type:\"string\"}\n",
    "target = \"Species\" #@param {type:\"string\"}\n",
    "experiment_id = \"08d03e85-4a7c-4376-873c-5828ea603e1f\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "Import and put the whole dataset in a pandas.DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import load_dataset\n",
    "\n",
    "df = load_dataset(name=dataset)\n",
    "X = df.drop(target, axis=1).to_numpy()\n",
    "y = df[target].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load metadata\n",
    "In this context, metadata means information about the dataset.<br>\n",
    "For example, below we get the feature type for each column in the dataset. (eg. categorical, numerical, or datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import load_metadata\n",
    "from platiagro.featuretypes import infer_featuretypes\n",
    "\n",
    "try:\n",
    "    metadata = load_metadata(name=dataset)\n",
    "    featuretypes = metadata[\"featuretypes\"]\n",
    "except KeyError:\n",
    "    featuretypes = infer_featuretypes(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorical features\n",
    "\n",
    "Many machine learning algorithms cannot operate on categorical data directly. They require all input variables and output variables to be numeric.<br>\n",
    "This means that categorical data must be converted to a numerical form.<br>\n",
    "The features are converted to ordinal integers. This results in a single column of integers (0 to n_categories - 1) per feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro.featuretypes import CATEGORICAL\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "target_idx = df.columns.tolist().index(target)\n",
    "# selects the categorical features\n",
    "categorical_idxs = [idx for idx, ft in enumerate(featuretypes) if ft == CATEGORICAL and idx != target_idx]\n",
    "feature_encoder = OrdinalEncoder()\n",
    "\n",
    "if len(categorical_idxs) > 0:\n",
    "    X[:, categorical_idxs] = feature_encoder.fit_transform(X[:, categorical_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode target labels\n",
    "\n",
    "The target labels are converted to ordinal integers with value between 0 and n_classes-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into train/test splits\n",
    "\n",
    "Training Dataset: the sample of data used to fit the model.\n",
    "\n",
    "Test Dataset: the sample of data used to provide an unbiased evaluation of a model fit on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a model using sklearn.ensemble.forest.RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble.forest import RandomForestClassifier\n",
    "\n",
    "estimator = RandomForestClassifier(n_estimators=10)\n",
    "estimator.fit(X_train, y_train)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure the performance\n",
    "The [**Confusion Matrix**](https://en.wikipedia.org/wiki/Confusion_matrix) is a performance measurement for machine learning classification.<br>\n",
    "It is extremely useful for measuring [Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification), [Recall, Precision, and F-measure](https://en.wikipedia.org/wiki/Precision_and_recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# uses the model to make predictions on the Test Dataset\n",
    "y_pred = estimator.predict(X_test)\n",
    "\n",
    "# computes confusion matrix\n",
    "labels = np.unique(y)\n",
    "data = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "\n",
    "# puts matrix in pandas.DataFrame for better format\n",
    "labels = label_encoder.inverse_transform(labels)\n",
    "confusion_matrix = pd.DataFrame(data, columns=labels, index=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save metrics\n",
    "\n",
    "Record the metrics used to evaluate the model.<br>\n",
    "It's a good way to document the experiments, and also help to avoid running the same experiment twice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_metrics\n",
    "\n",
    "save_metrics(experiment_id=experiment_id, confusion_matrix=confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model\n",
    "\n",
    "Stores the model artifacts in a object storage.<br>\n",
    "It will make the model available for future deployments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_model\n",
    "\n",
    "save_model(experiment_id=experiment_id, model={\"estimator\": estimator, \"feature_encoder\": feature_encoder, \"label_encoder\": label_encoder})"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
