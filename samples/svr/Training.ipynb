{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regression\n",
    "\n",
    "This is a component that trains a Support Vector Regression model using [Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html). \n",
    "<br>\n",
    "Scikit-learn is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection and evaluation, and many other utilities.\n",
    "\n",
    "This notebook shows:\n",
    "- how to use the [SDK](https://platiagro.github.io/sdk/) to load datasets, save models and other artifacts.\n",
    "- how to declare parameters and use them to build reusable components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare parameters\n",
    "Components may declare (and use) these default parameters:\n",
    "- dataset\n",
    "- target\n",
    "- experiment_id\n",
    "- operator_id\n",
    "\n",
    "Use these parameters to load/save datasets, models, metrics, and figures with the help of [PlatIAgro SDK](https://platiagro.github.io/sdk/).\n",
    "\n",
    "You may also declare custom parameters to set when running an experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = \"boston\" #@param {type:\"string\"}\n",
    "target = \"medv\" #@param {type:\"string\"}\n",
    "experiment_id = \"50ecf2eb-b805-4629-aea4-66053ed9ec8c\" #@param {type:\"string\"}\n",
    "operator_id = \"104740b1-82c1-4321-9bd3-b2ef931f56f1\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "Import and put the whole dataset in a pandas.DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import load_dataset\n",
    "\n",
    "df = load_dataset(name=dataset)\n",
    "X = df.drop(target, axis=1).to_numpy()\n",
    "y = df[target].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load metadata about the dataset\n",
    "For example, below we get the feature type for each column in the dataset. (eg. categorical, numerical, or datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from platiagro import stat_dataset\n",
    "from platiagro.featuretypes import infer_featuretypes\n",
    "\n",
    "try:\n",
    "    metadata = stat_dataset(name=dataset)\n",
    "    featuretypes = metadata[\"featuretypes\"]\n",
    "except KeyError:\n",
    "    featuretypes = infer_featuretypes(df)\n",
    "\n",
    "featuretypes = np.array(featuretypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace NaN values\n",
    "Remove features that all values are NA.<br>\n",
    "If some values are missing, then use the mean for numerical features, and the mode for categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_free = df.dropna(axis=\"columns\", how=\"all\")\n",
    "only_na = df.loc[:, ~df.columns.isin(na_free.columns)]\n",
    "\n",
    "featuretypes = featuretypes[df.columns.isin(na_free.columns)]\n",
    "df = na_free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro.featuretypes import CATEGORICAL, NUMERICAL\n",
    "\n",
    "numerical_indexes = (featuretypes == NUMERICAL)\n",
    "numerical_nan_replacement = df.iloc[:, numerical_indexes].mean(axis=0)\n",
    "df.fillna(numerical_nan_replacement, inplace=True)\n",
    "\n",
    "categorical_indexes = (featuretypes == CATEGORICAL)\n",
    "categorical_nan_replacement = df.iloc[:, categorical_indexes].mode(axis=0).iloc[0]\n",
    "df.fillna(categorical_nan_replacement, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(target, axis=1).to_numpy()\n",
    "columns = df.columns.to_numpy()\n",
    "target_index = np.argwhere(columns == target)\n",
    "columns = np.delete(columns, target_index)\n",
    "featuretypes = np.delete(featuretypes, target_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove datetime features\n",
    "Datetime columns require separate preprocessing or feature extraction steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro.featuretypes import DATETIME\n",
    "\n",
    "datetime_indexes = (featuretypes == DATETIME)\n",
    "X = X[:, np.where(~datetime_indexes)[0]]\n",
    "featuretypes = np.delete(featuretypes, np.where(datetime_indexes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorical features\n",
    "\n",
    "Many machine learning algorithms cannot operate on categorical data directly. They require all input variables and output variables to be numeric.<br>\n",
    "This means that categorical data must be converted to a numerical form.<br>\n",
    "The features are converted to ordinal integers. This results in a single column of integers (0 to n_categories - 1) per feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "categorical_indexes = (featuretypes == CATEGORICAL)\n",
    "feature_encoder = OrdinalEncoder()\n",
    "\n",
    "if np.ma.any(categorical_indexes):\n",
    "    X[:, categorical_indexes] = feature_encoder.fit_transform(X[:, categorical_indexes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into train/test splits\n",
    "\n",
    "Training Dataset: the sample of data used to fit the model.\n",
    "\n",
    "Test Dataset: the sample of data used to provide an unbiased evaluation of a model fit on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a model using sklearn.svm.SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "estimator = SVR(gamma=\"auto\")\n",
    "estimator.fit(X_train, y_train)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure the performance\n",
    "\n",
    "R² corresponds to the squared correlation between the observed outcome values and the predicted values by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# uses the model to make predictions on the Test Dataset\n",
    "y_pred = estimator.predict(X_test)\n",
    "\n",
    "# computes R²\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save metrics\n",
    "\n",
    "Record the metrics used to evaluate the model.<br>\n",
    "It's a good way to document the experiments, and also help to avoid running the same experiment twice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_metrics\n",
    "\n",
    "save_metrics(experiment_id=experiment_id, operator_id=operator_id, r2_score=r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save figure\n",
    "\n",
    "Record a matplotlib figure to document the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from platiagro import save_figure\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "def annotate_plot(e, s, plt, y_lim, h, abs_err):\n",
    "    if h < 2:\n",
    "        p = 0.05\n",
    "    else:\n",
    "        p = 0.1\n",
    "    plt.annotate(\"\", xy=(max(e), y_lim[1]/h),\n",
    "                 xytext=(0, y_lim[1]/h),\n",
    "                 arrowprops=dict(arrowstyle=\"->\"))\n",
    "    plt.annotate(\"\", xy=(min(e), y_lim[1]/h),\n",
    "                 xytext=(0, y_lim[1]/h),\n",
    "                 arrowprops=dict(arrowstyle=\"->\"))\n",
    "    plt.annotate(\"{}%\".format(s),\n",
    "                 xy=(0, (1+p)*y_lim[1]/h),\n",
    "                 ha=\"center\")\n",
    "    if abs_err:\n",
    "        plt.annotate(\"{:.2f}\".format(max(e)),\n",
    "                     xy=((0+max(e))/2, (1-p)*y_lim[1]/h),\n",
    "                     ha=\"center\")\n",
    "        plt.annotate(\"{:.2f}\".format(min(e)),\n",
    "                     xy=((0+min(e))/2, (1-p)*y_lim[1]/h),\n",
    "                     ha=\"center\")\n",
    "    else:\n",
    "        plt.annotate(\"{:.2f}%\".format(100*max(e)),\n",
    "                     xy=((0+max(e))/2, (1-p)*y_lim[1]/h),\n",
    "                     ha=\"center\")\n",
    "        plt.annotate(\"{:.2f}%\".format(100*min(e)),\n",
    "                     xy=((0+min(e))/2, (1-p)*y_lim[1]/h),\n",
    "                     ha=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_err = False\n",
    "if any(y_test==0):\n",
    "    err = y_pred - y_test\n",
    "    abs_err = True\n",
    "else:\n",
    "    err = (y_pred - y_test)/y_test\n",
    "\n",
    "sorted_idx = np.argsort(np.abs(err))\n",
    "n = int(0.7*len(y_test))\n",
    "idx = sorted_idx[:n]\n",
    "e = err[idx]\n",
    "\n",
    "n = int(0.95*len(y_test))\n",
    "idx = sorted_idx[:n]\n",
    "aux = err[idx]\n",
    "x_lim = (aux.min(), aux.max())\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "kde = gaussian_kde(err)\n",
    "x_err = np.linspace(err.min(), err.max(), 1000)\n",
    "p_err = kde(x_err)\n",
    "plt.plot(x_err, p_err, 'b-')\n",
    "\n",
    "y_lim = plt.ylim()\n",
    "plt.ylim((0, y_lim[1]))\n",
    "y_lim = plt.ylim()\n",
    "plt.xlim(x_lim)\n",
    "plt.plot([e.min(), e.min()], y_lim, \"r--\")\n",
    "plt.plot([e.max(), e.max()], y_lim, \"r--\")\n",
    "\n",
    "# Shade the area between e.min() and e.max()\n",
    "plt.fill_betweenx(y_lim, e.min(), e.max(),\n",
    "                  facecolor=\"red\",  # The fill color\n",
    "                  color=\"red\",      # The outline color\n",
    "                  alpha=0.2)        # Transparency of the fill\n",
    "\n",
    "annotate_plot(e, 70, plt, y_lim, 2, abs_err)\n",
    "annotate_plot(aux, 95, plt, y_lim, 1.2, abs_err)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.title(\"Error Distribution\")\n",
    "\n",
    "save_figure(experiment_id=experiment_id, operator_id=operator_id, figure=plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model\n",
    "\n",
    "Stores the model artifacts in a object storage.<br>\n",
    "It will make the model available for future deployments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_model\n",
    "\n",
    "save_model(experiment_id=experiment_id,\n",
    "           model={\"estimator\": estimator,\n",
    "                  \"feature_encoder\": feature_encoder,\n",
    "                  \"columns\": columns,\n",
    "                  \"datetime_indexes\": datetime_indexes,\n",
    "                  \"categorical_indexes\": categorical_indexes,\n",
    "                  \"numerical_nan_replacement\": numerical_nan_replacement,\n",
    "                  \"categorical_nan_replacement\": categorical_nan_replacement})"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}