{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Classification\n",
    "\n",
    "This is a component that performs predictions using a Support Vector Classification implementation from [Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html). \n",
    "<br>\n",
    "Scikit-learn is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection and evaluation, and many other utilities.\n",
    "\n",
    "This notebook shows:\n",
    "- how to use SDK to load a model.\n",
    "- how to use a model to provide real-time predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Predictor.py\n",
    "import logging\n",
    "from typing import List, Iterable, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from platiagro import load_model, load_metadata, load_dataset\n",
    "from platiagro.featuretypes import CATEGORICAL, NUMERICAL, infer_featuretypes\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class Predictor(object):\n",
    "    \"\"\"\n",
    "    Model template. You can load your model parameters in __init__ from a location accessible at runtime.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset=None, target=None, experiment_id=None):\n",
    "        \"\"\"\n",
    "        Add any initialization parameters. These will be passed at runtime from the graph definition parameters defined in your seldondeployment kubernetes resource manifest.\n",
    "        \"\"\"\n",
    "        logger.info(\"Initializing\")\n",
    "\n",
    "        # Loads Estimator and Label Encoders\n",
    "        model = load_model(name=experiment_id)\n",
    "        self.estimator = model[\"estimator\"]\n",
    "        self.les = model[\"label_encoder\"]\n",
    "\n",
    "        # Loads Column Names and Feature Types\n",
    "        df = load_dataset(name=dataset)\n",
    "        self.columns = df.columns.values.tolist()\n",
    "        self.featuretypes = infer_featuretypes(df)\n",
    "\n",
    "        # Finds the Feature Type for target variable \n",
    "        target_idx = self.columns.index(target)\n",
    "        self.problem_type = self.featuretypes.pop(target_idx)\n",
    "\n",
    "        logger.info(\"Init complete!\")\n",
    "\n",
    "    def predict(self, X: np.ndarray, feature_names: Iterable[str]) -> Union[np.ndarray, List, str, bytes]:\n",
    "        \"\"\"Returns a prediction.\n",
    "\n",
    "        Args:\n",
    "            X (numpy.array): Array-like with data.\n",
    "            feature_names (iterable, optional): Array of feature names.\n",
    "\n",
    "        Returns:\n",
    "            Array-like with predictions.\n",
    "        \"\"\"\n",
    "        logger.info(\"Predict called - will run predictions\")\n",
    "\n",
    "        # Builds a DataFrame from numpy.array.\n",
    "        df = pd.DataFrame(X, columns=feature_names)\n",
    "\n",
    "        # Encodes categorical features\n",
    "        idx = 0\n",
    "        for i, ft in enumerate(self.featuretypes):\n",
    "            if ft == CATEGORICAL:\n",
    "                x = df.iloc[:, i]\n",
    "                df[df.columns[i]] = self.les[idx].transform(x)\n",
    "                idx += 1\n",
    "\n",
    "        # Replaces NaNs\n",
    "        for i, col in enumerate(df.columns):\n",
    "            ft = self.featuretypes[i]\n",
    "            if ft == CATEGORICAL:\n",
    "                sub = df[col].mode()[0]\n",
    "                df[col].fillna(sub, inplace=True)\n",
    "            elif ft == NUMERICAL:\n",
    "                sub = df[col].mean()\n",
    "                df[col].fillna(sub, inplace=True)\n",
    "\n",
    "        # Performs Prediction\n",
    "        X_predict = self.estimator.predict(df.to_numpy())\n",
    "\n",
    "        # Applies Label Decoder for Classification Tasks\n",
    "        if self.problem_type == CATEGORICAL:\n",
    "            X_predict = self.les[-1].inverse_transform(X_predict)\n",
    "\n",
    "        return X_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment Test\n",
    "\n",
    "It simulates a model deployed by PlatIAgro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "MODEL_NAME=Predictor\n",
    "API_TYPE=REST\n",
    "SERVICE_TYPE=MODEL\n",
    "PERSISTENCE=0\n",
    "LOG_LEVEL=DEBUG\n",
    "PARAMETERS='[{\"type\":\"STRING\",\"name\":\"dataset\",\"value\":\"iris\"},{\"type\":\"STRING\",\"name\":\"target\",\"value\":\"Species\"},{\"type\":\"STRING\",\"name\":\"experiment_id\",\"value\":\"99284308-cd3f-47d4-ab71-9c57acbb4d7b\"}]'\n",
    "\n",
    "seldon-core-microservice $MODEL_NAME $API_TYPE \\\n",
    "    --service-type $SERVICE_TYPE \\\n",
    "    --persistence $PERSISTENCE \\\n",
    "    --parameters $PARAMETERS \\\n",
    "    --log-level $LOG_LEVEL > log.txt 2>&1 &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl localhost:5000/predict -d 'json={\"data\":{\"names\":[\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"], \"ndarray\":[[5.1, 3.5, 1.4, 0.2]]}}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ps -ef | grep [s]eldon-core-microservice | awk '{print $2}' | xargs -r kill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
