{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression (aka logit, MaxEnt) classifier - Experiment\n",
    "\n",
    "This is a component that trains a Logistic Regression (aka logit, MaxEnt) classifier model using [Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). \n",
    "<br>\n",
    "Scikit-learn is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection and evaluation, and many other utilities.\n",
    "\n",
    "This notebook shows:\n",
    "- how to use the [SDK](https://platiagro.github.io/sdk/) to load datasets, save models and other artifacts.\n",
    "- how to declare parameters and use them to build reusable components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare parameters and model hyperparameters\n",
    "Components may declare (and use) these default parameters:\n",
    "- dataset\n",
    "- target\n",
    "\n",
    "Use these parameters to load/save datasets, models, metrics, and figures with the help of [PlatIAgro SDK](https://platiagro.github.io/sdk/). <br />\n",
    "You may also declare custom parameters to set when running an experiment.\n",
    "\n",
    "Select the hyperparameters and their respective values to be used when training the model:\n",
    "- solver\n",
    "- penalty\n",
    "- C\n",
    "- fit_intercept\n",
    "- class_weight\n",
    "- max_iter\n",
    "- multi_class\n",
    "\n",
    "These parameters are just a few offered by the model class, you may also use another existing parameter. <br />\n",
    "Check the [model parameters](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "dataset = \"iris\" #@param {type:\"string\"}\n",
    "target = \"Species\" #@param {type:\"feature\", label:\"Atributo alvo\", description: \"Seu modelo será treinado para prever os valores do alvo.\"}\n",
    "\n",
    "# selected features to perform the model\n",
    "model_features = [\"SepalLengthCm\",\"SepalWidthCm\",\"PetalLengthCm\"] #@param {type:\"feature\",multiple:true,label:\"Features selecionadas para o modelo\",description:\"Seu modelo será feito considerando apenas as features selecionadas. Caso não selecione nenhuma, todas as features serão utilizadas\"}\n",
    "\n",
    "# features to apply Ordinal Encoder\n",
    "ordinal_features = \"\" #@param {type:\"feature\",multiple:true,label:\"Features para fazer codificação ordinal\", description: \"Seu modelo utilizará a codificação ordinal para as features selecionadas. As demais features categóricas serão codificadas utilizando One-Hot-Encoding.\"}\n",
    "\n",
    "# hyperparameters\n",
    "penalty = \"l2\" #@param [\"l1, \"l2\", \"elasticnet\", \"None\"] {type:\"string\", label:\"Penalidade\", description:\"Norma utilizada na penalização do erro\"}\n",
    "C = 1.0 #@param {type:\"number\", label:\"Regularização Inversa\", description:\"Retém a modificação de força da regularização ao ser posicionada inversamente no regulador Lambda\"}\n",
    "fit_intercept = True #@param {type\"boolean\", label:\"Interceptação\", description:\"Especifica se uma constante (viés ou interceptação) deve ser adicionada à função de decisão\"}\n",
    "class_weight = None #@param [\"balanced”, “balanced_subsample”] {type:\"string\", label:\"Peso das Classes\", description:\"Especifica pesos de amostras quando for ajustar classificadores como uma função da classe do target\"}\n",
    "solver = \"liblinear\" #@param [\"lbfgs\", \"sgd\", \"adam\"] {type:\"string\", label:\"Solucionador\", description:\"Algoritmo a ser usado no problema de otimização\"}\n",
    "max_iter = 100 #@param {type: \"integer\", label:\"Iterações\", description:\"Número máximo de itereações feitas para os solvers convergirem\"}\n",
    "multi_class = \"auto\" #@param [\"auto\", \"ovr\", \"multimomial\"] {type:\"string\", label:\"Multiclasse\", description:\"Classificação com mais de duas classes, porém cada amostra pode ser rotulada apenas como uma classe\"}\n",
    "\n",
    "# predict method\n",
    "method = \"predict_proba\" #@param [\"predict_proba\", \"predict\"] {type:\"string\", label:\"Método de Predição\", description:\"Se optar por 'predict_proba', o método de predição será a probabilidade estimada de cada classe, já o 'predict' prediz a qual classe pertence\"} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "Import and put the whole dataset in a pandas.DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import load_dataset\n",
    "\n",
    "df = load_dataset(name=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load metadata about the dataset\n",
    "For example, below we get the feature type for each column in the dataset. (eg. categorical, numerical, or datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from platiagro import stat_dataset\n",
    "\n",
    "metadata = stat_dataset(name=dataset)\n",
    "featuretypes = metadata[\"featuretypes\"]\n",
    "\n",
    "columns = df.columns.to_numpy()\n",
    "featuretypes = np.array(featuretypes)\n",
    "target_index = np.argwhere(columns == target)\n",
    "columns = np.delete(columns, target_index)\n",
    "featuretypes = np.delete(featuretypes, target_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode target labels\n",
    "\n",
    "The target labels are converted to ordinal integers with value between 0 and n_classes-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into train/test splits\n",
    "\n",
    "Training Dataset: the sample of data used to fit the model.\n",
    "\n",
    "Test Dataset: the sample of data used to provide an unbiased evaluation of a model fit on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep selected features to perform the model\n",
    "\n",
    "Select only the features that should be used in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(model_features)>=1:\n",
    "    columns_index = (np.where(np.isin(columns,model_features)))[0]\n",
    "    columns_index.sort()\n",
    "    columns = columns[columns_index]\n",
    "    featuretypes = featuretypes[columns_index]\n",
    "\n",
    "#keep the features selected in model_features parameter\n",
    "df_model = df[columns]\n",
    "X = df_model.to_numpy()\n",
    "y = df[target].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro.featuretypes import NUMERICAL\n",
    "\n",
    "# Selects the indexes of numerical and non-numerical features\n",
    "numerical_indexes = np.where(featuretypes == NUMERICAL)[0]\n",
    "non_numerical_indexes = np.where(~(featuretypes == NUMERICAL))[0]\n",
    "\n",
    "# Selects non-numerical features to apply ordinal encoder or one-hot encoder\n",
    "ordinal_features = np.asarray(ordinal_features)\n",
    "non_numerical_indexes_ordinal = np.where(~(featuretypes == NUMERICAL) & np.isin(columns,ordinal_features))[0]\n",
    "non_numerical_indexes_one_hot = np.where(~(featuretypes == NUMERICAL) & ~(np.isin(columns,ordinal_features)))[0]\n",
    "\n",
    "# After the step handle_missing_values, \n",
    "# numerical features are grouped in the beggining of the array\n",
    "numerical_indexes_after_handle_missing_values = \\\n",
    "    np.arange(len(numerical_indexes))\n",
    "non_numerical_indexes_after_handle_missing_values = \\\n",
    "    np.arange(len(numerical_indexes), len(featuretypes))\n",
    "one_hot_indexes_after_handle_missing_values = non_numerical_indexes_after_handle_missing_values[np.where(np.isin(non_numerical_indexes,non_numerical_indexes_one_hot))[0]]         \n",
    "ordinal_indexes_after_handle_missing_values = non_numerical_indexes_after_handle_missing_values[np.where(np.isin(non_numerical_indexes,non_numerical_indexes_ordinal))[0]]                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a model using sklearn.linear_model.LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "from category_encoders.one_hot import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('handle_missing_values',\n",
    "     ColumnTransformer(\n",
    "        [('imputer_mean', SimpleImputer(strategy='mean'), numerical_indexes),\n",
    "         ('imputer_mode', SimpleImputer(strategy='most_frequent'), non_numerical_indexes)],\n",
    "         remainder='drop')),\n",
    "    ('handle_categorical_features',\n",
    "     ColumnTransformer(\n",
    "         [('feature_encoder_ordinal', OrdinalEncoder(), ordinal_indexes_after_handle_missing_values),\n",
    "          ('feature_encoder_onehot', OneHotEncoder(), one_hot_indexes_after_handle_missing_values)],\n",
    "         remainder='passthrough')),\n",
    "    ('estimator', LogisticRegression(solver=solver,\n",
    "                                     penalty=penalty,\n",
    "                                     C=C,\n",
    "                                     fit_intercept=fit_intercept,\n",
    "                                     class_weight=class_weight,\n",
    "                                     max_iter=max_iter,\n",
    "                                     multi_class=multi_class))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure the performance\n",
    "The [**Confusion Matrix**](https://en.wikipedia.org/wiki/Confusion_matrix) is a performance measurement for machine learning classification.<br>\n",
    "It is extremely useful for measuring [Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification), [Recall, Precision, and F-measure](https://en.wikipedia.org/wiki/Precision_and_recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "# uses the model to make predictions on the Test Dataset\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_prob = pipeline.predict_proba(X_test)\n",
    "\n",
    "# computes confusion matrix\n",
    "labels = np.unique(y)\n",
    "data = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "\n",
    "# computes precision, recall, f1-score, support (for multiclass classification problem) and accuracy\n",
    "if len(labels)>2:  #multiclass classification\n",
    "    p, r, f1, s = precision_recall_fscore_support(y_test, y_pred,\n",
    "                                                  labels=labels,\n",
    "                                                  average=None)\n",
    "    \n",
    "    commom_metrics = pd.DataFrame(data=zip(p, r, f1, s),columns=['Precision','Recall','F1-Score','Support']) \n",
    "    \n",
    "    average_options = ('micro', 'macro', 'weighted')\n",
    "    for average in average_options:\n",
    "        if average.startswith('micro'):\n",
    "            line_heading = 'accuracy'\n",
    "        else:\n",
    "            line_heading = average + ' avg'\n",
    "\n",
    "        # compute averages with specified averaging method\n",
    "        avg_p, avg_r, avg_f1, _ = precision_recall_fscore_support(\n",
    "            y_test, y_pred, labels=labels,\n",
    "            average=average)\n",
    "        avg = pd.Series({'Precision':avg_p,  'Recall':avg_r,  'F1-Score':avg_f1,  'Support':np.sum(s)},name=line_heading)\n",
    "        commom_metrics = commom_metrics.append(avg)\n",
    "else: #binary classification\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_test, y_pred,\n",
    "                                                  average='binary')\n",
    "    accuracy=accuracy_score(y_test, y_pred)\n",
    "    commom_metrics = pd.DataFrame(data={'Precision':p,'Recall':r,'F1-Score':f1,'Accuracy':accuracy},index=[1])\n",
    "\n",
    "# puts matrix in pandas.DataFrame for better format\n",
    "labels = label_encoder.inverse_transform(labels)\n",
    "confusion_matrix = pd.DataFrame(data, columns=labels, index=labels)\n",
    "\n",
    "# add correct index labels to commom_metrics DataFrame (for multiclass classification)\n",
    "if len(labels)>2:\n",
    "    as_list = commom_metrics.index.tolist()\n",
    "    as_list[0:len(labels)] = labels\n",
    "    commom_metrics.index = as_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save metrics\n",
    "\n",
    "Record the metrics used to evaluate the model.<br>\n",
    "It's a good way to document the experiments, and also help to avoid running the same experiment twice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_metrics\n",
    "\n",
    "save_metrics(confusion_matrix=confusion_matrix,commom_metrics=commom_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save figure\n",
    "\n",
    "Compute and plot Compute Receiver operating characteristic (ROC) curve to evaluate the model performance. It illustrates the performance of a binary classifier system as its discrimination threshold is varied. For multiclass classification task, it is used the one-vs-rest algorithm, that is, computes the AUC of each class against the rest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import preprocessing\n",
    "from numpy import unique\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "\n",
    "y_prob = pipeline.predict_proba(X_test)\n",
    "\n",
    "def plot_roc_curve(y_test,y_prob,labels):\n",
    "    n_classes = len(labels)\n",
    "    \n",
    "    if n_classes == 2:\n",
    "        # Compute ROC curve \n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob[:, 1])\n",
    "        roc_auc = auc(fpr, tpr)  \n",
    "        \n",
    "        # Plot ROC Curve\n",
    "        plt.figure()\n",
    "        lw = 2\n",
    "        plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "        plt.xlim([-0.01, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "        \n",
    "    else:  \n",
    "        # Binarize the output\n",
    "        lb = preprocessing.LabelBinarizer()\n",
    "        y_test_bin = lb.fit_transform(y_test)\n",
    "\n",
    "        # Compute ROC curve for each class\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()  \n",
    "\n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        \n",
    "        color=cm.rainbow(np.linspace(0,1,n_classes+1))\n",
    "        plt.figure()\n",
    "        lw = 2\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "        plt.xlim([-0.01, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        \n",
    "        for i,c in zip(range(n_classes),color):                   \n",
    "            plt.plot(fpr[i], tpr[i], color=c,\n",
    "             lw=lw, label='ROC curve - Class %s (area = %0.2f)' % (labels[i] ,roc_auc[i]))\n",
    "            plt.title('ROC Curve One-vs-Rest')\n",
    "            plt.legend(loc=\"lower right\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "from platiagro import save_figure\n",
    "from platiagro import list_figures\n",
    "\n",
    "plot_roc_curve(y_test,y_prob,labels)\n",
    "\n",
    "save_figure(figure=plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataset\n",
    "\n",
    "Add model result to the dataset and stores the transformed dataset in a object storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_dataset\n",
    "from re import sub\n",
    "\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "new_columns = list()\n",
    "if method == \"predict_proba\":\n",
    "    y_pred = pipeline.predict_proba(X)\n",
    "    for i,class_j in zip(range(len(labels)),labels):\n",
    "        new_columns.append(sub('[^a-zA-Z0-9\\n\\.]', '_', str('Logistic_'+ method + '_' + str(class_j))))\n",
    "        df[new_columns[i]] = y_pred[:,i]\n",
    "else:\n",
    "    y_pred = pipeline.predict(X)\n",
    "    y_pred = label_encoder.inverse_transform(y_pred)\n",
    "    new_columns.append('Logistic_'+ method )\n",
    "    df[new_columns[0]] = y_pred\n",
    "\n",
    "save_dataset(name=dataset, df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model\n",
    "\n",
    "Stores the model artifacts in a object storage.<br>\n",
    "It will make the model available for future deployments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_model\n",
    "\n",
    "save_model(columns=columns,\n",
    "           label_encoder=label_encoder,\n",
    "           pipeline=pipeline,\n",
    "           method=method,\n",
    "           new_columns=new_columns)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "experiment_id": "7315b5a1-0692-4711-921d-5570f28c2a76",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "operator_id": "07091821-9548-410f-a359-9266c9c75c79"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
