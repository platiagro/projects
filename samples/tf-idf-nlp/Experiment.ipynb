{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Frequency–Inverse Document Frequency (TF-IDF) - Experimento\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.\n",
    "\n",
    "Este notebook apresenta:\n",
    "- como usar o [SDK](https://platiagro.github.io/sdk/) para carregar datasets, salvar modelos e outros artefatos.\n",
    "- como declarar parâmetros e usá-los para criar componentes reutilizáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare parâmetros e hiperparâmetros para o modelo\n",
    "Os componentes podem declarar (e usar) estes parâmetros como padrão:\n",
    "- dataset\n",
    "- target\n",
    "\n",
    "Use estes parâmetros para carregar/salvar conjutos de dados, modelos, métricas e figuras com a ajuda do [SDK da PlatIAgro](https://platiagro.github.io/sdk/). <br>\n",
    "É possível também declarar parâmetros personalizados para serem definidos ao executar um experimento. \n",
    "\n",
    "Selecione os hiperparâmetros e seus respectivos valores para serem usados ao treinar o modelo:\n",
    "- language\n",
    "\n",
    "Estes parâmetros são alguns dos oferecidos pela classe do modelo, você também pode utilizar outros existentes. <br>\n",
    "Dê uma olhada nos [parâmetros do modelo](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn-impute-simpleimputer) para mais informações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parâmetros\n",
    "dataset = \"imdb\" #@param {type:\"string\"}\n",
    "target = \"label\" #@param {type:\"feature\", label:\"Atributo alvo\", description:\"Seu modelo será treinado para prever os valores do alvo.\"}\n",
    "text = \"text\" #@param {type:\"string\", label:\"Texto alvo\", description:\"Nome da coluna do texto alvo pertencente ao dataset.\"}\n",
    "language = \"english\" #@param [\"portuguese\", \"english\"] {type:\"string\", label:\"Linguagem\", description:\"Linguagem da qual os stopwords pertencem. Deve ser a mesma utilizada no dataset.\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "Import and put the whole dataset in a pandas.DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import load_dataset\n",
    "\n",
    "df = load_dataset(name=dataset)\n",
    "X = df[text].to_numpy()\n",
    "y = df[target].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acesso ao conjunto de dados\n",
    "\n",
    "Utiliza a função load_dataset do [SDK da PlatIAgro](https://platiagro.github.io/sdk/) para carregar conjuntos de dados.\n",
    "O tipo da variável retornada depende do arquivo de origem:\n",
    "- [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) para CSV e compressed CSV: .csv .csv.zip .csv.gz .csv.bz2 .csv.xz\n",
    "- [Binary IO stream](https://docs.python.org/3/library/io.html#binary-i-o) para outros tipos de arquivo: .jpg .wav .zip .h5 .parquet etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from platiagro import stat_dataset\n",
    "\n",
    "metadata = stat_dataset(name=dataset)\n",
    "featuretypes = metadata[\"featuretypes\"]\n",
    "\n",
    "columns = df.columns.to_numpy()\n",
    "featuretypes = np.array(featuretypes)\n",
    "target_index = np.argwhere(columns == target)\n",
    "columns = np.delete(columns, target_index)\n",
    "featuretypes = np.delete(featuretypes, target_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão do datset em subconjuntos de treino e teste\n",
    "\n",
    "Subconjunto de Treino: amostras de dados usado para treinar o modelo (``fit``). <br>\n",
    "Subconjunto de Teste: a amostra de dados usada para fornecer uma avaliação imparcial de um modelo adequado ao conjunto de dados de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busca por stopwords\n",
    "\n",
    "Stopwords (ou palavras de parada) são palavras que geralmente se referem às mais comuns em um idioma ou em um corpus. <br>\n",
    "Elas podem ser ignoradas com segurança sem sacrificar o significado da frase, pois são palarvas que não agregram muito significado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# Download stopwords from nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Get a list of stopwords for the defined language\n",
    "stopwords = nltk.corpus.stopwords.words(language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento do texto\n",
    "\n",
    "Funções auxiliares para processamento dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import sub\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "def tokenize_without_punctuation(text_list: list = None):\n",
    "    \"\"\"Tokenize without ponctuation.\n",
    "\n",
    "    Args:\n",
    "        text_list (list): a list of texts to be used.\n",
    "\n",
    "    Returns:\n",
    "        A list of tokenized text without punctuation.\n",
    "    \"\"\"\n",
    "    tokenize_list = list()\n",
    "    punctuation_pattern = \"[^a-zA-Z0-9áéíóúÁÉÍÓÚâêîôÂÊÎÔãõÃÕçÇ ]\"\n",
    "    html_tag_pattern = \"<.*?>\"\n",
    "\n",
    "    for text in text_list:\n",
    "        text = sub(html_tag_pattern, ' ', text)\n",
    "        tokenize_list.append(sub(punctuation_pattern, ' ', text).split(' '))\n",
    "\n",
    "    return tokenize_list\n",
    "\n",
    "\n",
    "def top_tokens_stopwords(token_list: list, percentage: float = 0.01):\n",
    "    \"\"\"Selects the most relevant stops words of the tokerized texts.\n",
    "\n",
    "    Args:\n",
    "        token_list (list): list of tokens.\n",
    "        percentage (float): percentage threshold.\n",
    "    \"\"\"\n",
    "    vocabulary = defaultdict(int)\n",
    "\n",
    "    for sample in token_list:\n",
    "        for token in sample:\n",
    "            vocabulary[token] += 1\n",
    "\n",
    "    all_tokens = sorted(vocabulary.items(), key=lambda token: token[1], reverse=True)\n",
    "    top_tokens = all_tokens[:int(len(all_tokens) * percentage)]\n",
    "\n",
    "    return [token[0] for token in top_tokens]\n",
    "\n",
    "\n",
    "def remove_specific_tokens(token_list: list, tokens_to_be_removed: list = None):\n",
    "    \"\"\"Removes specific tokens from a token list.\n",
    "\n",
    "    Args:\n",
    "        token_list (list): list of tokens from which other tokens will be removed.\n",
    "        tokens_to_be_removed (list): list of tokens that need to be removed.\n",
    "    \"\"\"\n",
    "    token_list_ = list()\n",
    "\n",
    "    if tokens_to_be_removed is None:\n",
    "        tokens_to_be_removed = top_tokens_stopwords(token_list)\n",
    "\n",
    "    for sample in token_list:\n",
    "        sample = list(set(sample) - set(tokens_to_be_removed))\n",
    "        token_list_.append(sample)\n",
    "\n",
    "    return token_list_\n",
    "\n",
    "\n",
    "def token_restructuring(token_list: list):\n",
    "    \"\"\"Reduce a nested list of tokens to a single list (1D).\n",
    "    \n",
    "    Args:\n",
    "        token_list (list): list to be work on.\n",
    "    \"\"\"\n",
    "    return reduce(lambda x, y: x + y, token_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treina modelo usando sklearn.feature_extraction.text.TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "tokenize_without_punctuation_ = FunctionTransformer(tokenize_without_punctuation, validate=False)\n",
    "remove_specific_tokens_ = FunctionTransformer(remove_specific_tokens, validate=False)\n",
    "token_restructuring_ = FunctionTransformer(token_restructuring, validate=False)\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('remove_punctuation', tokenize_without_punctuation_),\n",
    "    ('remove_top_tokens', remove_specific_tokens_),\n",
    "    ('restructuring', token_restructuring_),\n",
    "    ('estimator', TfidfVectorizer())\n",
    "])\n",
    "\n",
    "tdidf_matrix = pipeline.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva métricas\n",
    "\n",
    "Utiliza a função `save_metrics` do [SDK da PlatIAgro](https://platiagro.github.io/sdk/) para salvar métricas. Por exemplo: `accuracy`, `precision`, `r2_score`, `custom_score` etc.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_dataset\n",
    "\n",
    "save_dataset(name=dataset, df=pd.DataFrame(tdidf_matrix.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva modelo e outros artefatos\n",
    "\n",
    "Utiliza a função `save_model` do [SDK da PlatIAgro](https://platiagro.github.io/sdk/) para salvar modelos e outros artefatos.<br>\n",
    "Essa função torna estes artefatos disponíveis para o notebook de implantação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_model\n",
    "\n",
    "save_model(pipeline=pipeline)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "experiment_id": "ab814fda-ef4a-4cc6-9d83-a050094fb5aa",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "operator_id": "b8719065-0e88-4198-9635-33a3832f90e4"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
