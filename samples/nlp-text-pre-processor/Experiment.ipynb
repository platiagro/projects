{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VfGzS7lzmZr3"
   },
   "source": [
    "# Text Pre Processor - Experimento\n",
    "\n",
    "Este é um componente que utiliza a biblioteca [nltk](https://www.nltk.org/) e [ftfy](https://pypi.org/project/ftfy/) e [regex](https://docs.python.org/3/library/re.html) para pré processar textos que entrrão em outros componentes.\n",
    "\n",
    "Este notebook apresenta:\n",
    "- como usar o [SDK](https://platiagro.github.io/sdk/) para carregar datasets, salvar modelos e outros artefatos.\n",
    "- como declarar parâmetros e usá-los para criar componentes reutilizáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tD7cOYh6mZr5"
   },
   "source": [
    "## Declaração de parâmetros e hiperparâmetros\n",
    "\n",
    "Declare parâmetros com o botão <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAABhWlDQ1BJQ0MgcHJvZmlsZQAAKJF9kT1Iw0AcxV9TtaIVBzuIOASpThb8QhylikWwUNoKrTqYXPohNGlIUlwcBdeCgx+LVQcXZ10dXAVB8APEydFJ0UVK/F9SaBHjwXE/3t173L0DhFqJqWbbGKBqlpGMRcVMdkUMvKID3QhiCOMSM/V4aiENz/F1Dx9f7yI8y/vcn6NHyZkM8InEs0w3LOJ14ulNS+e8TxxiRUkhPiceNeiCxI9cl11+41xwWOCZISOdnCMOEYuFFpZbmBUNlXiKOKyoGuULGZcVzluc1VKFNe7JXxjMacsprtMcRAyLiCMBETIq2EAJFiK0aqSYSNJ+1MM/4PgT5JLJtQFGjnmUoUJy/OB/8LtbMz854SYFo0D7i21/DAOBXaBete3vY9uunwD+Z+BKa/rLNWDmk/RqUwsfAb3bwMV1U5P3gMsdoP9JlwzJkfw0hXweeD+jb8oCfbdA16rbW2Mfpw9AmrpaugEODoGRAmWveby7s7W3f880+vsBocZyukMJsmwAAAAGYktHRAD/AP8A/6C9p5MAAAAJcEhZcwAADdcAAA3XAUIom3gAAAAHdElNRQfkBgsMIwnXL7c0AAACDUlEQVQ4y92UP4gTQRTGf29zJxhJZ2NxbMBKziYWlmJ/ile44Nlkd+dIYWFzItiNgoIEtFaTzF5Ac/inE/urtLWxsMqmUOwCEpt1Zmw2xxKi53XitPO9H9978+aDf/3IUQvSNG0450Yi0jXG7C/eB0cFeu9viciGiDyNoqh2KFBrHSilWstgnU7nFLBTgl+ur6/7PwK11kGe5z3n3Hul1MaiuCgKDZwALHA7z/Oe1jpYCtRaB+PxuA8kQM1aW68Kt7e3zwBp6a5b1ibj8bhfhQYVZwMRiQHrvW9nWfaqCrTWPgRWvPdvsiy7IyLXgEJE4slk8nw+T5nDgDbwE9gyxryuwpRSF5xz+0BhrT07HA4/AyRJchUYASvAbhiGaRVWLIMBYq3tAojIszkMoNRulbXtPM8HwV/sXSQi54HvQRDcO0wfhGGYArvAKjAq2wAgiqJj3vsHpbtur9f7Vi2utLx60LLW2hljEuBJOYu9OI6vAzQajRvAaeBLURSPlsBelA+VhWGYaq3dwaZvbm6+m06noYicE5ErrVbrK3AXqHvvd4bD4Ye5No7jSERGwKr3Pms2m0pr7Rb30DWbTQWYcnFvAieBT7PZbFB1V6vVfpQaU4UtDQetdTCZTC557/eA48BlY8zbRZ1SqrW2tvaxCvtt2iRJ0i9/xb4x5uJRwmNlaaaJ3AfqIvKY/+78Av++6uiSZhYMAAAAAElFTkSuQmCC\" /> na barra de ferramentas.<br>\n",
    "O parâmetro `dataset` identifica os conjuntos de dados. Você pode importar arquivos de dataset com o botão <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAABhWlDQ1BJQ0MgcHJvZmlsZQAAKJF9kT1Iw0AcxV9TtaIVBzuIOASpThb8QhylikWwUNoKrTqYXPohNGlIUlwcBdeCgx+LVQcXZ10dXAVB8APEydFJ0UVK/F9SaBHjwXE/3t173L0DhFqJqWbbGKBqlpGMRcVMdkUMvKID3QhiCOMSM/V4aiENz/F1Dx9f7yI8y/vcn6NHyZkM8InEs0w3LOJ14ulNS+e8TxxiRUkhPiceNeiCxI9cl11+41xwWOCZISOdnCMOEYuFFpZbmBUNlXiKOKyoGuULGZcVzluc1VKFNe7JXxjMacsprtMcRAyLiCMBETIq2EAJFiK0aqSYSNJ+1MM/4PgT5JLJtQFGjnmUoUJy/OB/8LtbMz854SYFo0D7i21/DAOBXaBete3vY9uunwD+Z+BKa/rLNWDmk/RqUwsfAb3bwMV1U5P3gMsdoP9JlwzJkfw0hXweeD+jb8oCfbdA16rbW2Mfpw9AmrpaugEODoGRAmWveby7s7W3f880+vsBocZyukMJsmwAAAAGYktHRAD/AP8A/6C9p5MAAAAJcEhZcwAADdcAAA3XAUIom3gAAAAHdElNRQfkBgsOBy6ASTeXAAAC/0lEQVQ4y5WUT2gcdRTHP29m99B23Uiq6dZisgoWCxVJW0oL9dqLfyhCvGWY2YUBI95MsXgwFISirQcLhS5hfgk5CF3wJIhFI7aHNsL2VFZFik1jS1qkiZKdTTKZ3/MyDWuz0fQLc/m99/vMvDfv+4RMlUrlkKqeAAaBAWAP8DSgwJ/AXRG5rao/WWsvTU5O3qKLBMD3fSMiPluXFZEPoyj67PGAMzw83PeEMABHVT/oGpiamnoAmCcEWhH5tFsgF4bh9oWFhfeKxeJ5a+0JVT0oImWgBPQCKfAQuAvcBq67rltX1b+6ApMkKRcKhe9V9QLwbavV+qRer692Sx4ZGSnEcXw0TdP3gSrQswGYz+d/S5IkVtXTwOlCoZAGQXAfmAdagAvsAErtdnuXiDy6+023l7qNRsMODg5+CawBzwB9wFPA7mx8ns/KL2Tl3xCRz5eWlkabzebahrHxPG+v4zgnc7ncufHx8Z+Hhoa29fT0lNM03Q30ikiqqg+ttX/EcTy3WTvWgdVqtddaOw/kgXvADHBHROZVNRaRvKruUNU+EdkPfGWM+WJTYOaSt1T1LPDS/4zLWWPMaLVaPWytrYvIaBRFl/4F9H2/JCKvGmMu+76/X0QOqGoZKDmOs1NV28AicMsYc97zvFdc1/0hG6kEeNsY83UnsCwivwM3VfU7YEZE7lhr74tIK8tbnJiYWPY8b6/ruleAXR0ftQy8boyZXi85CIIICDYpc2ZgYODY3NzcHmvt1eyvP64lETkeRdE1yZyixWLx5U2c8q4x5mIQBE1g33/0d3FlZeXFR06ZttZesNZejuO4q1NE5CPgWVV9E3ij47wB1IDlJEn+ljAM86urq7+KyAtZTgqsO0VV247jnOnv7/9xbGzMViqVMVX9uANYj6LonfVtU6vVkjRNj6jqGeCXzGrPAQeA10TkuKpOz87ONrayhnIA2Qo7BZwKw3B7kiRloKSqO13Xja21C47jPNgysFO1Wi0GmtmzQap6DWgD24A1Vb3SGf8Hfstmz1CuXEIAAAAASUVORK5CYII=\" /> na barra de ferramentas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jK9Bd6X7mZr6",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parâmetros\n",
    "dataset = \"/tmp/data/imdb-2.csv\" #@param {type:\"string\"}\n",
    "target = \"sentiment\" #@param {type:\"string\", label:\"Atributo alvo\", description:\"Seu modelo será treinado para prever os valores do alvo.\"}\n",
    "language = \"english\" #@param [\"portuguese\", \"english\"] {type:\"string\", label:\"Linguagem\", description:\"Linguagem da qual os stopwords pertencem. Deve ser a mesma utilizada no dataset.\"}\n",
    "\n",
    "# selected features to perform the model\n",
    "filter_type = \"incluir\" #@param [\"incluir\",\"remover\"] {type:\"string\",label:\"Modo de seleção das features\", description:\"Se deseja informar quais features deseja incluir no modelo, selecione a opção [incluir]. Caso deseje informar as features que não devem ser utilizadas, selecione [remover].\"}\n",
    "#model_features = \"review\" #@param {type:\"string\",multiple:true,label:\"Features para incluir/remover no modelo\",description:\"Seu modelo será feito considerando apenas as features selecionadas. Caso nada seja especificado, todas as features serão utilizadas\"}\n",
    "model_features = \"review\" #@param {type:\"string\"}\n",
    "\n",
    "# preprocessamento\n",
    "case = \"Lower\" #@param [\"Lower\",\"Upper\",\"NotApply\"] {type:\"string\",label:\"Aplicação de casing\", description:\"Caixa baixa, caixa alta ou não aplicação de caixa\"}\n",
    "remove_stop_words = True #@param {type:\"boolean\",label:\"Remoção de Stop Words\", description:\"Remoção de palavras, conjunções, artigos e outros\"}\n",
    "remove_top_words = True #@param {type:\"boolean\",label:\"Remoção de Top Words\", description:\"Remoção dea porcentagem palavras mais frequentes no texto\"}\n",
    "top_words_percentage = 0.01 #@param {type:\"number\",label:\"Porcentagem de Top Words\", description:\"Porcentagem das palavras mais frequentes no texto\"}\n",
    "stemming = False #@param {type:\"boolean\",label:\"Stemming\"}\n",
    "lemmatization = True #@param {type:\"boolean\",label:\"Lemmatization\"}\n",
    "remove_punctuation = True #@param {type:\"boolean\",label:\"Remoção de pontuação\"}\n",
    "remove_line_braks = True #@param {type:\"boolean\",label:\"Remoção de quebras de lina\",description:\"Remoção de quebras de linha por \\n e \\r\"}\n",
    "remove_accents = True #@param {type:\"boolean\",label:\"Remoção de acentos\"}\n",
    "remove_html = True #@param {type:\"boolean\",label:\"Remoção de HTML\"}\n",
    "remove_css = True #@param {type:\"boolean\",label:\"Remoção de CSS\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nsJMgpBRmZr_"
   },
   "source": [
    "## Acesso ao conjunto de dados\n",
    "\n",
    "O conjunto de dados utilizado nesta etapa será o mesmo carregado através da plataforma.<br>\n",
    "O tipo da variável retornada depende do arquivo de origem:\n",
    "- [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) para CSV e compressed CSV: .csv .csv.zip .csv.gz .csv.bz2 .csv.xz\n",
    "- [Binary IO stream](https://docs.python.org/3/library/io.html#binary-i-o) para outros tipos de arquivo: .jpg .wav .zip .h5 .parquet etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dzan1wl1mZr_",
    "outputId": "b893eabd-dbe5-46a8-bc26-81a96418dc8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review sentiment\n",
      "0      One of the other reviewers has mentioned that ...  positive\n",
      "1      A wonderful little production. <br /><br />The...  positive\n",
      "2      I thought this was a wonderful way to spend ti...  positive\n",
      "3      Basically there's a family where a little boy ...  negative\n",
      "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "...                                                  ...       ...\n",
      "49995  I thought this movie did a down right good job...  positive\n",
      "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
      "49997  I am a Catholic taught in parochial elementary...  negative\n",
      "49998  I'm going to have to disagree with the previou...  negative\n",
      "49999  No one expects the Star Trek movies to be high...  negative\n",
      "\n",
      "[50000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(dataset)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "duCQT-2YmZsF"
   },
   "source": [
    "## Acesso aos metadados do conjunto de dados\n",
    "\n",
    "Utiliza a função `stat_dataset` do [SDK da PlatIAgro](https://platiagro.github.io/sdk/) para carregar metadados. <br>\n",
    "Por exemplo, arquivos CSV possuem `metadata['featuretypes']` para cada coluna no conjunto de dados (ex: categorical, numerical, or datetime)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qyNVXA7CmZsG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from platiagro import stat_dataset\n",
    "\n",
    "#metadata = stat_dataset(name=dataset)\n",
    "#featuretypes = metadata[\"featuretypes\"]\n",
    "\n",
    "columns = df.columns.to_numpy()\n",
    "#featuretypes = np.array(featuretypes)\n",
    "target_index = np.argwhere(columns == target)\n",
    "columns = np.delete(columns, target_index)\n",
    "#featuretypes = np.delete(featuretypes, target_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qtyfRV_0mZsJ"
   },
   "source": [
    "## Remoção de linhas com valores faltantes no atributo alvo\n",
    "\n",
    "Caso haja linhas em que o atributo alvo contenha valores faltantes, é feita a remoção dos casos faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vh8OXGLImZsK"
   },
   "outputs": [],
   "source": [
    "df.dropna(subset = [target],inplace=True)\n",
    "df.dropna(subset = [model_features],inplace=True)\n",
    "y = df[target].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bRlxsXqwmZsO"
   },
   "source": [
    "## Filtragem das features \n",
    "\n",
    "Seleciona apenas as features que foram declaradas no parâmetro model_features. Se nenhuma feature for especificada, todo o conjunto de dados será utilizado para a modelagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B2viBFvUmZsP"
   },
   "outputs": [],
   "source": [
    "if filter_type == 'incluir':\n",
    "    if len(model_features) >= 1:\n",
    "        columns_index = (np.where(np.isin(columns,model_features)))[0]\n",
    "        columns_index.sort()\n",
    "        columns_to_filter = columns[columns_index]\n",
    "        #featuretypes = featuretypes[columns_index]\n",
    "    else:\n",
    "        columns_to_filter = columns\n",
    "else:\n",
    "    if len(model_features) >= 1:\n",
    "        columns_index = (np.where(np.isin(columns,model_features)))[0]\n",
    "        columns_index.sort()\n",
    "        columns_to_filter = np.delete(columns,columns_index)\n",
    "        #featuretypes = np.delete(featuretypes,columns_index)\n",
    "    else:\n",
    "        columns_to_filter = columns\n",
    "\n",
    "# keep the features selected\n",
    "df_model = df[columns_to_filter]\n",
    "X = df_model.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dUySX0csmZsT"
   },
   "source": [
    "## Codifica labels do atributo alvo\n",
    "\n",
    "As labels do atributo alvo são convertidos em números inteiros ordinais com valor entre 0 e n_classes-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OBbq--yEmZsU"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tqtHW62PmZsc"
   },
   "source": [
    "## Definição dos filtros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "colab_type": "code",
    "id": "Ic4xH_S3mZsg",
    "outputId": "37afeb30-6cb0-43d3-c272-e9ed67a8fbb9"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "from re import sub\n",
    "\n",
    "import unidecode\n",
    "from ftfy import fix_text\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "def tokenize_text(text_list: list = None):\n",
    "    \"\"\"Tokenize Text without the hyperparâmeters defined.\n",
    "\n",
    "    Args:\n",
    "        text_list (list): a list of texts to be used.\n",
    "\n",
    "    Returns:\n",
    "        A list of tokenized text without punctuation.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenize_list = list()\n",
    "    for text in text_list:\n",
    "        text = text[0]\n",
    "        text = fix_text(text)\n",
    "        text = sub(\"<.*?>\", \" \", text) if remove_html else text\n",
    "        text = sub(\"{.*?}\", \" \", text) if remove_css else text\n",
    "        text = unidecode.unidecode(text) if remove_accents else text\n",
    "        text = sub(\"/\\r\\n|\\n|\\r|\", \"\", text) if remove_line_braks else text\n",
    "        text = (\n",
    "            sub(\"[\" + string.punctuation + \"]\", \"\", text)\n",
    "            if remove_punctuation\n",
    "            else text\n",
    "        )\n",
    "        text = sub(\" +\", \" \", text)  # only to avoid multiple spaces\n",
    "        text = text.split(\" \")\n",
    "\n",
    "        tokenize_list.append(text)\n",
    "    return tokenize_list\n",
    "\n",
    "\n",
    "def top_tokens_stopwords(sentence_list: list, percentage: float = 0.01):\n",
    "    \"\"\"Selects the most relevant stops words of the tokerized texts.\n",
    "\n",
    "    Args:\n",
    "        sentence_list (list): list of tokens.\n",
    "        percentage (float): percentage threshold.\n",
    "    \"\"\"\n",
    "    percentage = top_words_percentage\n",
    "    vocabulary = defaultdict(int)\n",
    "\n",
    "    for sample in sentence_list:\n",
    "        for token in sample:\n",
    "            vocabulary[token] += 1\n",
    "\n",
    "    all_tokens = sorted(vocabulary.items(), key=lambda token: token[1], reverse=True)\n",
    "    top_tokens = all_tokens[: int(len(all_tokens) * percentage)]\n",
    "\n",
    "    return [token[0] for token in top_tokens]\n",
    "\n",
    "\n",
    "def remove_specific_tokens(sentence_list: list, tokens_to_be_removed: list = None):\n",
    "    \"\"\"Removes specific tokens from a token list.\n",
    "\n",
    "    Args:\n",
    "        sentence_list (list): list of tokens from which other tokens will be removed.\n",
    "        tokens_to_be_removed (list): list of tokens that need to be removed.\n",
    "    \"\"\"\n",
    "    sentence_list_ = list()\n",
    "    sentence_list_ = [x for x in sentence_list if x not in tokens_to_be_removed]\n",
    "\n",
    "    return sentence_list_\n",
    "\n",
    "\n",
    "def apply_stemming(sentence_list: list):\n",
    "    ps = PorterStemmer()\n",
    "    sentence_list = [\n",
    "        [ps.stem(word) for word in token_list] for token_list in sentence_list\n",
    "    ]\n",
    "    return sentence_list\n",
    "\n",
    "\n",
    "def apply_lemmatization(sentence_list: list):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    sentence_list = [\n",
    "        [lemmatizer.lemmatize(word) for word in token_list]\n",
    "        for token_list in sentence_list\n",
    "    ]\n",
    "    return sentence_list\n",
    "\n",
    "\n",
    "def apply_casing(sentence_list: list, case: str):\n",
    "    if case == \"Lower\":\n",
    "        sentence_list = [\n",
    "            [word.lower() for word in token_list] for token_list in sentence_list\n",
    "        ]\n",
    "    elif case == \"Upper\":\n",
    "        sentence_list = [\n",
    "            [word.upper() for word in token_list] for token_list in sentence_list\n",
    "        ]\n",
    "    else:\n",
    "        pass\n",
    "    return sentence_list\n",
    "\n",
    "\n",
    "def token_restructuring(sentence_list: list):\n",
    "    \"\"\"Reduce a nested list of tokens to a single list (1D).\n",
    "\n",
    "    Args:\n",
    "        sentence_list (list): list to be work on.\n",
    "    \"\"\"\n",
    "    return reduce(lambda x, y: x + y, sentence_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "miiSextFmZso"
   },
   "source": [
    "## Aplicação dos filtros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QUZAOGE8mZso"
   },
   "source": [
    "Baixando stop words do idioma especificado e a wordnet para lemmatizaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oWSBNLFamZsp",
    "outputId": "13c97fdc-8719-4ba0-a457-e51dc2ee196c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "if remove_stop_words:\n",
    "    # Download stopwords from nltk\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "    # Get a list of stopwords for the defined language\n",
    "    stopwords = nltk.corpus.stopwords.words(language)\n",
    "\n",
    "if lemmatization:\n",
    "    nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nB4iSRIOmZst"
   },
   "source": [
    "Aplicando pré processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fmu-I2rTmZsw"
   },
   "outputs": [],
   "source": [
    "vocab = tokenize_text(X)\n",
    "top_tokens = top_tokens_stopwords(vocab) if remove_top_words else None\n",
    "vocab = remove_specific_tokens(vocab,top_tokens) if remove_top_words else vocab\n",
    "vocab = remove_specific_tokens(vocab,stopwords) if remove_stop_words else vocab\n",
    "vocab = apply_stemming(vocab) if stemming else vocab\n",
    "vocab = apply_lemmatization(vocab) if lemmatization else vocab\n",
    "vocab = apply_casing(vocab,case)\n",
    "text = [' '.join(tokens) for tokens in vocab]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l0K6F2vSmZsz"
   },
   "source": [
    "## Salva alterações no conjunto de dados\n",
    "\n",
    "O conjunto de dados será salvo (e sobrescrito com as respectivas mudanças) localmente, no container da experimentação, utilizando a função `pandas.DataFrame.to_csv`.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HnP9SI5wmZs0",
    "outputId": "df0b124e-41cd-49ca-cf11-6459746b7fa1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewer ha mentioned that af...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production the filming tech...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this wa a wonderful way to spend tim...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there a family where a little boy ja...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love in the time of money is a ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>im going to have to disagree with the previous...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movie to be high ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one of the other reviewer ha mentioned that af...  positive\n",
       "1      a wonderful little production the filming tech...  positive\n",
       "2      i thought this wa a wonderful way to spend tim...  positive\n",
       "3      basically there a family where a little boy ja...  negative\n",
       "4      petter matteis love in the time of money is a ...  positive\n",
       "...                                                  ...       ...\n",
       "49995  i thought this movie did a down right good job...  positive\n",
       "49996  bad plot bad dialogue bad acting idiotic direc...  negative\n",
       "49997  i am a catholic taught in parochial elementary...  negative\n",
       "49998  im going to have to disagree with the previous...  negative\n",
       "49999  no one expects the star trek movie to be high ...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dec = list(label_encoder.inverse_transform(y))\n",
    "new_columns = ['review', 'sentiment']\n",
    "df_result = pd.DataFrame(list(zip(text, y_dec)),columns = new_columns) \n",
    "#save dataset changes\n",
    "df_result.to_csv(dataset, index=False)\n",
    "df_result"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "name": "Experiment.ipynb",
   "provenance": []
  },
  "experiment_id": "c5fdb533-1571-45fc-990a-bd9964aa1ea0",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "operator_id": "ebed0565-a0ee-427a-b490-d8cca8cb0241",
  "task_id": "cb77e87e-8bd9-4d6f-94d2-cb3c06f2e152"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
