{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Selection\n",
    "\n",
    "Remove specifics features from dataset.\n",
    "\n",
    "This notebook shows:\n",
    "- how to use the [SDK](https://platiagro.github.io/sdk/) to load datasets, save models and other artifacts.\n",
    "- how to declare parameters and use them to build reusable components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare parameters and model hyperparameters\n",
    "Components may declare (and use) these default parameters:\n",
    "- dataset\n",
    "\n",
    "Use these parameters to load/save datasets, models, metrics, and figures with the help of [PlatIAgro SDK](https://platiagro.github.io/sdk/). <br />\n",
    "You may also declare custom parameters to set when running an experiment.\n",
    "\n",
    "Select the hyperparameters and their respective values to be used when training the model:\n",
    "- features_to_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "dataset = \"iris\" #@param {type:\"string\"}\n",
    "target = \"Species\" #@param {type:\"feature\", label:\"Atributo alvo\", description: \"Seu modelo ser√° treinado para prever os valores do alvo.\"}\n",
    "\n",
    "# hyperparameters\n",
    "features_to_filter = [\"SepalWidthCm\", \"SepalLengthCm\"] #@param {type:\"list\", label:\"Features Para Filtragem\", description:\"Remove features selecionadas do dataset.\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "Import and put the whole dataset in a pandas.DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import load_dataset\n",
    "\n",
    "df = load_dataset(name=dataset)\n",
    "X = df.drop(target, axis=1).to_numpy()\n",
    "y = df[target].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load metadata about the dataset\n",
    "For example, below we get the feature type for each column in the dataset. (eg. categorical, numerical, or datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from platiagro import stat_dataset\n",
    "\n",
    "metadata = stat_dataset(name=dataset)\n",
    "featuretypes = metadata[\"featuretypes\"]\n",
    "\n",
    "columns = df.columns.to_numpy()\n",
    "featuretypes = np.array(featuretypes)\n",
    "target_index = np.argwhere(columns == target)\n",
    "columns = np.delete(columns, target_index)\n",
    "featuretypes = np.delete(featuretypes, target_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping custom transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile CustomTransformer.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class Filter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features, columns):\n",
    "        self.features = features\n",
    "        self.columns = columns\n",
    "    \n",
    "    def fit(self, X=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, input_series):\n",
    "        \"\"\"Remove features from dataset\"\"\"\n",
    "        indexes = np.where(np.in1d(self.columns, self.features))[0]\n",
    "        return np.delete(input_series, indexes, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from CustomTransformer import Filter\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Call changes\n",
    "pipeline = make_pipeline(\n",
    "    Filter(features=features_to_filter, columns=columns)\n",
    ")\n",
    "\n",
    "# Transform `X`\n",
    "X = pipeline.transform(X)\n",
    "\n",
    "# Put back in pd.DataFrame\n",
    "features_after_pipeline = columns[~np.in1d(columns, features_to_filter), ...]\n",
    "df = pd.DataFrame(X, columns=features_after_pipeline)\n",
    "df[target] = pd.Series(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataset\n",
    "\n",
    "Stores the transformed dataset in a object storage.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_dataset\n",
    "\n",
    "save_dataset(name=dataset, df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model\n",
    "\n",
    "Stores the model artifacts in a object storage.<br>\n",
    "It will make the model available for future deployments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_model\n",
    "\n",
    "save_model(pipeline=pipeline,\n",
    "           columns=columns)"
   ]
  }
 ],
 "metadata": {
  "experiment_id": "baa4dfa2-9ebb-11ea-bb37-0242ac130002",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "operator_id": "c2dc16f4-9ebb-11ea-bb37-0242ac130002"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
