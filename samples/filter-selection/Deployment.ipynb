{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Selection - Deployment\n",
    "\n",
    "Remove specifics features from dataset.\n",
    "\n",
    "This notebook shows:\n",
    "- how to use the [SDK](https://platiagro.github.io/sdk/) to load datasets, save models and other artifacts.\n",
    "- how to declare parameters and use them to build reusable components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile CustomTransformer.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class Filter(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Feature selector that removes specific features.\n",
    "    \n",
    "    This feature selection algorithm looks only at the columns\n",
    "    and then remove the selected ones.\n",
    "    \n",
    "    Attributes:\n",
    "        features_to_remove: A list of features to be removed.\n",
    "        dataset_columns: An np.ndarray with the current features of the dataset.\n",
    "        drop_indexes: An list of indexes to be droped.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, features_to_remove: list, dataset_columns: np.ndarray):\n",
    "        \"\"\"Inits Filter class.\n",
    "        \n",
    "        Args:\n",
    "            features: features to be removed.\n",
    "            columns: columns of the dataset.\n",
    "        \"\"\"\n",
    "        self.features_to_remove = features_to_remove\n",
    "        self.dataset_columns = dataset_columns\n",
    "    \n",
    "    def transform(self, X: np.ndarray):\n",
    "        \"\"\"Reduce X to the selected features.\n",
    "        \n",
    "        Args:\n",
    "            X: the input samples.\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: the input samples with only the selected features.\n",
    "        \"\"\"\n",
    "        return np.delete(X, self.drop_indexes, axis=1)\n",
    "    \n",
    "    def fit(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Fit the model.\n",
    "        \n",
    "        Learn selected features index.\n",
    "        \n",
    "        Args:\n",
    "            X: the imput sample.\n",
    "        \n",
    "        Returns:\n",
    "            self\n",
    "        \"\"\"\n",
    "        if set(self.features_to_remove).issubset(self.dataset_columns):\n",
    "            self.drop_indexes = np.where(np.in1d(self.dataset_columns,\n",
    "                                                 self.features_to_remove))[0]\n",
    "            return self\n",
    "        else:\n",
    "            raise ValueError(f\"Dataset has no {self.features_to_remove} features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping Model\n",
    "\n",
    "Allows your component to expose a service over REST.\n",
    "\n",
    "To wrap your model [follow the instructions](https://docs.seldon.io/projects/seldon-core/en/v0.3.0/python/python_component.html) for your chosen language or toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Model.py\n",
    "import logging\n",
    "from typing import List, Iterable, Dict, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from platiagro import load_model\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class Model(object):    \n",
    "    def __init__(self, dataset: str = None, target: str = None):\n",
    "        # Load Artifacts: Estimator, etc\n",
    "        model = load_model()\n",
    "        self.pipeline = model[\"pipeline\"]\n",
    "        self.features_names_training = model[\"columns\"]\n",
    "        self.features_after_pipeline = model[\"features_after_pipeline\"]\n",
    "\n",
    "    def class_names(self):\n",
    "        return self.features_after_pipeline.tolist()\n",
    "\n",
    "    def predict(self, X: np.ndarray, feature_names: Iterable[str], meta: Dict = None) -> Union[np.ndarray, List, str, bytes]:\n",
    "        \"\"\"Takes an array (numpy) X and feature_names and completes missing values.\n",
    "\n",
    "        Args:\n",
    "            X (numpy.array): Array-like with data.\n",
    "            feature_names (iterable, optional): Array of feature names.\n",
    "            meta (dict, optional): Dict of metadata.\n",
    "        \"\"\"\n",
    "        if feature_names:\n",
    "            # Before feeding the model with `X`, resort its features like the training data\n",
    "            df = pd.DataFrame(X, columns=feature_names)\n",
    "            X = df[self.features_names_training].to_numpy()\n",
    "\n",
    "        # Perform Transformation\n",
    "        X = self.pipeline.transform(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Contract\n",
    "\n",
    "There are two sections:\n",
    "\n",
    "- `features` : The feature array you intend to send in a request\n",
    "- `targets` : The response you expect back\n",
    "\n",
    "Each section has a list of definitions. Each definition consists of:\n",
    "\n",
    "- `name` : String : The name of the feature\n",
    "- `ftype` : one of CONTINUOUS, CATEGORICAL : the type of the feature\n",
    "- `dtype` : One of FLOAT, INT : Required for ftype CONTINUOUS : What type of feature to create\n",
    "- `values` : list of Strings : Required for ftype CATEGORICAL : The possible categorical values\n",
    "- `range` : list of two numbers : Optional for ftype CONTINUOUS : The range of values (inclusive) that a continuous value can take\n",
    "- `repeat` : integer : Optional value for how many times to repeat this value\n",
    "- `shape` : array of integers : Optional value for the shape of array to coerce the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile contract.json\n",
    "{\n",
    "    \"features\": [\n",
    "        {\n",
    "            \"name\": \"SepalLengthCm\",\n",
    "            \"dtype\": \"FLOAT\",\n",
    "            \"ftype\": \"continuous\",\n",
    "            \"range\": [0.0, 7.0]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"SepalWidthCm\",\n",
    "            \"dtype\": \"FLOAT\",\n",
    "            \"ftype\": \"continuous\",\n",
    "            \"range\": [0.0, 4.0]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"PetalLengthCm\",\n",
    "            \"dtype\": \"FLOAT\",\n",
    "            \"ftype\": \"continuous\",\n",
    "            \"range\": [0.0, 7.0]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"PetalWidthCm\",\n",
    "            \"dtype\": \"FLOAT\",\n",
    "            \"ftype\": \"continuous\",\n",
    "            \"range\": [0.1, 3.0]\n",
    "        }\n",
    "    ],\n",
    "    \"targets\": [\n",
    "        {\n",
    "            \"name\": \"SepalLengthCm\",\n",
    "            \"dtype\": \"FLOAT\",\n",
    "            \"ftype\": \"continuous\",\n",
    "            \"range\": [0.0, 7.0]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"SepalWidthCm\",\n",
    "            \"dtype\": \"FLOAT\",\n",
    "            \"ftype\": \"continuous\",\n",
    "            \"range\": [0.0, 4.0]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"PetalLengthCm\",\n",
    "            \"dtype\": \"FLOAT\",\n",
    "            \"ftype\": \"continuous\",\n",
    "            \"range\": [0.0, 7.0]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"PetalWidthCm\",\n",
    "            \"dtype\": \"FLOAT\",\n",
    "            \"ftype\": \"continuous\",\n",
    "            \"range\": [0.0, 3.0]\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Deployment\n",
    "\n",
    "Starts a service wrapping a Model, sends a request to the service, and shows the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro.deployment import test_deployment\n",
    "\n",
    "test_deployment(\"contract.json\")"
   ]
  }
 ],
 "metadata": {
  "experiment_id": "baa4dfa2-9ebb-11ea-bb37-0242ac130002",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "operator_id": "c2dc16f4-9ebb-11ea-bb37-0242ac130002"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
