{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML Regressor\n",
    "\n",
    "This is a component that trains an AutoML Regressor model using [auto-sklearn](https://github.com/automl/auto-sklearn). \n",
    "<br>\n",
    "auto-sklearn is an automated machine learning toolkit and a drop-in replacement for a scikit-learn estimator.\n",
    "\n",
    "This notebook shows:\n",
    "- how to use the [SDK](https://platiagro.github.io/sdk/) to load datasets, save models and other artifacts.\n",
    "- how to declare parameters and use them to build reusable components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare parameters and model hyperparameters\n",
    "Components may declare (and use) these default parameters:\n",
    "- dataset\n",
    "- target\n",
    "Use these parameters to load/save datasets, models, metrics, and figures with the help of [PlatIAgro SDK](https://platiagro.github.io/sdk/). <br />\n",
    "You may also declare custom parameters to set when running an experiment.\n",
    "\n",
    "Select the hyperparameters and their respective values to be used when training the model:\n",
    "- time_left_for_this_task\n",
    "- per_run_time_limit\n",
    "- ensemble_size\n",
    "\n",
    "These parameters are just a few offered by the model class, you may also use another existing parameter. <br />\n",
    "Check the [model parameters](https://automl.github.io/auto-sklearn/master/api.html#autosklearn.regression.AutoSklearnRegressor) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "dataset = \"boston\" #@param {type:\"string\"}\n",
    "target = \"medv\" #@param {type:\"feature\", label:\"Atributo alvo\", description: \"Seu modelo será treinado para prever os valores do alvo.\"}\n",
    "\n",
    "# hyperparameters\n",
    "time_left_for_this_task = 60 #@param {type:\"integer\", label:\"Limite de tempo (em segundos)\"}\n",
    "per_run_time_limit = 60 #@param {type:\"integer\", label:\"Limite de tempo (em segundos)\"}\n",
    "ensemble_size = 50 #@param {type:\"integer\", label:\"Ensemble Learning\", description:\"Número de modelos adicionados ao conjunto criado pela seleção do Ensemble das bibliotecas de modelos\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "Import and put the whole dataset in a pandas.DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import load_dataset\n",
    "\n",
    "df = load_dataset(name=dataset)\n",
    "X = df.drop(target, axis=1).to_numpy()\n",
    "y = df[target].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load metadata about the dataset\n",
    "For example, below we get the feature type for each column in the dataset. (eg. categorical, numerical, or datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from platiagro import stat_dataset\n",
    "\n",
    "metadata = stat_dataset(name=dataset)\n",
    "featuretypes = metadata[\"featuretypes\"]\n",
    "\n",
    "columns = df.columns.to_numpy()\n",
    "featuretypes = np.array(featuretypes)\n",
    "target_index = np.argwhere(columns == target)\n",
    "columns = np.delete(columns, target_index)\n",
    "featuretypes = np.delete(featuretypes, target_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode target labels\n",
    "\n",
    "The target labels are converted to ordinal integers with value between 0 and n_classes-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into train/test splits\n",
    "\n",
    "Training Dataset: the sample of data used to fit the model.\n",
    "\n",
    "Test Dataset: the sample of data used to provide an unbiased evaluation of a model fit on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro.featuretypes import NUMERICAL\n",
    "\n",
    "# Selects the indexes of numerical and non-numerical features\n",
    "numerical_indexes = np.where(featuretypes == NUMERICAL)[0]\n",
    "non_numerical_indexes = np.where(~(featuretypes == NUMERICAL))[0]\n",
    "\n",
    "# After the step handle_missing_values, \n",
    "# numerical features are grouped in the beggining of the array\n",
    "numerical_indexes_after_handle_missing_values = \\\n",
    "    np.arange(len(numerical_indexes))\n",
    "non_numerical_indexes_after_handle_missing_values = \\\n",
    "    np.arange(len(numerical_indexes), len(featuretypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a model using autosklearn.regression.AutoSklearnRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from autosklearn.regression import AutoSklearnRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numerical_indexes = (featuretypes == NUMERICAL)\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('handle missing values',\n",
    "     ColumnTransformer(\n",
    "         [('imputer_mean', SimpleImputer(strategy='mean'), numerical_indexes),\n",
    "          ('imputer_mode', SimpleImputer(strategy='most_frequent'), non_numerical_indexes)],\n",
    "         remainder='drop')),\n",
    "    ('handle categorical features',\n",
    "     ColumnTransformer(\n",
    "         [('feature_encoder', OrdinalEncoder(), non_numerical_indexes_after_handle_missing_values)],\n",
    "         remainder='passthrough')),\n",
    "    ('estimator', AutoSklearnRegressor(time_left_for_this_task=time_left_for_this_task,\n",
    "                                       per_run_time_limit=per_run_time_limit,\n",
    "                                       ensemble_size=ensemble_size)),\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "X_train = Pipeline(pipeline.steps[:-1]).transform(X_train)\n",
    "pipeline.named_steps.estimator.refit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure the performance\n",
    "\n",
    "R² corresponds to the squared correlation between the observed outcome values and the predicted values by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# uses the model to make predictions on the Test Dataset\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# computes R²\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save metrics\n",
    "\n",
    "Record the metrics used to evaluate the model.<br>\n",
    "It's a good way to document the experiments, and also help to avoid running the same experiment twice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_metrics\n",
    "\n",
    "save_metrics(r2_score=r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save figure\n",
    "\n",
    "Record a matplotlib figure to document the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from platiagro import save_figure\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "def annotate_plot(e, s, plt, y_lim, h, abs_err):\n",
    "    if h < 2:\n",
    "        p = 0.05\n",
    "    else:\n",
    "        p = 0.1\n",
    "    plt.annotate(\"\", xy=(max(e), y_lim[1]/h),\n",
    "                 xytext=(0, y_lim[1]/h),\n",
    "                 arrowprops=dict(arrowstyle=\"->\"))\n",
    "    plt.annotate(\"\", xy=(min(e), y_lim[1]/h),\n",
    "                 xytext=(0, y_lim[1]/h),\n",
    "                 arrowprops=dict(arrowstyle=\"->\"))\n",
    "    plt.annotate(\"{}%\".format(s),\n",
    "                 xy=(0, (1+p)*y_lim[1]/h),\n",
    "                 ha=\"center\")\n",
    "    if abs_err:\n",
    "        plt.annotate(\"{:.2f}\".format(max(e)),\n",
    "                     xy=((0+max(e))/2, (1-p)*y_lim[1]/h),\n",
    "                     ha=\"center\")\n",
    "        plt.annotate(\"{:.2f}\".format(min(e)),\n",
    "                     xy=((0+min(e))/2, (1-p)*y_lim[1]/h),\n",
    "                     ha=\"center\")\n",
    "    else:\n",
    "        plt.annotate(\"{:.2f}%\".format(100*max(e)),\n",
    "                     xy=((0+max(e))/2, (1-p)*y_lim[1]/h),\n",
    "                     ha=\"center\")\n",
    "        plt.annotate(\"{:.2f}%\".format(100*min(e)),\n",
    "                     xy=((0+min(e))/2, (1-p)*y_lim[1]/h),\n",
    "                     ha=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_err = False\n",
    "if any(y_test==0):\n",
    "    err = y_pred - y_test\n",
    "    abs_err = True\n",
    "else:\n",
    "    err = (y_pred - y_test)/y_test\n",
    "\n",
    "sorted_idx = np.argsort(np.abs(err))\n",
    "n = int(0.7*len(y_test))\n",
    "idx = sorted_idx[:n]\n",
    "e = err[idx]\n",
    "\n",
    "n = int(0.95*len(y_test))\n",
    "idx = sorted_idx[:n]\n",
    "aux = err[idx]\n",
    "x_lim = (aux.min(), aux.max())\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "kde = gaussian_kde(err)\n",
    "x_err = np.linspace(err.min(), err.max(), 1000)\n",
    "p_err = kde(x_err)\n",
    "plt.plot(x_err, p_err, 'b-')\n",
    "\n",
    "y_lim = plt.ylim()\n",
    "plt.ylim((0, y_lim[1]))\n",
    "y_lim = plt.ylim()\n",
    "plt.xlim(x_lim)\n",
    "plt.plot([e.min(), e.min()], y_lim, \"r--\")\n",
    "plt.plot([e.max(), e.max()], y_lim, \"r--\")\n",
    "\n",
    "# Shade the area between e.min() and e.max()\n",
    "plt.fill_betweenx(y_lim, e.min(), e.max(),\n",
    "                  facecolor=\"red\",  # The fill color\n",
    "                  color=\"red\",      # The outline color\n",
    "                  alpha=0.2)        # Transparency of the fill\n",
    "\n",
    "annotate_plot(e, 70, plt, y_lim, 2, abs_err)\n",
    "annotate_plot(aux, 95, plt, y_lim, 1.2, abs_err)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.title(\"Error Distribution\")\n",
    "\n",
    "save_figure(figure=plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model\n",
    "\n",
    "Stores the model artifacts in a object storage.<br>\n",
    "It will make the model available for future deployments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_model\n",
    "\n",
    "save_model(pipeline=pipeline, columns=columns)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "experiment_id": "6db0fff7-ba9d-4f64-8cbe-9a31bd8b3644",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "operator_id": "1fbe7220-0b4b-4eb6-aba2-b8afec49250d"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
