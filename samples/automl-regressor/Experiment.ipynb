{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressor AutoML - Experimento\n",
    "\n",
    "Este é um componente que utiliza a biblioteca [auto-sklearn](https://github.com/automl/auto-sklearn) para obter um ou mais modelos regressores já otimizados. <br>\n",
    "O auto-sklearn é um kit de ferramentas de machine learning automatizado e um substituto para [estimator](https://scikit-learn.org/stable/glossary.html#term-estimators) do [scikit-learn](https://scikit-learn.org/stable/).\n",
    "\n",
    "Este notebook apresenta:\n",
    "- como usar o [SDK](https://platiagro.github.io/sdk/) para carregar datasets, salvar modelos e outros artefatos.\n",
    "- como declarar parâmetros e usá-los para criar componentes reutilizáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaração de parâmetros e hiperparâmetros\n",
    "\n",
    "Declare parâmetros com o botão <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAABhWlDQ1BJQ0MgcHJvZmlsZQAAKJF9kT1Iw0AcxV9TtaIVBzuIOASpThb8QhylikWwUNoKrTqYXPohNGlIUlwcBdeCgx+LVQcXZ10dXAVB8APEydFJ0UVK/F9SaBHjwXE/3t173L0DhFqJqWbbGKBqlpGMRcVMdkUMvKID3QhiCOMSM/V4aiENz/F1Dx9f7yI8y/vcn6NHyZkM8InEs0w3LOJ14ulNS+e8TxxiRUkhPiceNeiCxI9cl11+41xwWOCZISOdnCMOEYuFFpZbmBUNlXiKOKyoGuULGZcVzluc1VKFNe7JXxjMacsprtMcRAyLiCMBETIq2EAJFiK0aqSYSNJ+1MM/4PgT5JLJtQFGjnmUoUJy/OB/8LtbMz854SYFo0D7i21/DAOBXaBete3vY9uunwD+Z+BKa/rLNWDmk/RqUwsfAb3bwMV1U5P3gMsdoP9JlwzJkfw0hXweeD+jb8oCfbdA16rbW2Mfpw9AmrpaugEODoGRAmWveby7s7W3f880+vsBocZyukMJsmwAAAAGYktHRAD/AP8A/6C9p5MAAAAJcEhZcwAADdcAAA3XAUIom3gAAAAHdElNRQfkBgsMIwnXL7c0AAACDUlEQVQ4y92UP4gTQRTGf29zJxhJZ2NxbMBKziYWlmJ/ile44Nlkd+dIYWFzItiNgoIEtFaTzF5Ac/inE/urtLWxsMqmUOwCEpt1Zmw2xxKi53XitPO9H9978+aDf/3IUQvSNG0450Yi0jXG7C/eB0cFeu9viciGiDyNoqh2KFBrHSilWstgnU7nFLBTgl+ur6/7PwK11kGe5z3n3Hul1MaiuCgKDZwALHA7z/Oe1jpYCtRaB+PxuA8kQM1aW68Kt7e3zwBp6a5b1ibj8bhfhQYVZwMRiQHrvW9nWfaqCrTWPgRWvPdvsiy7IyLXgEJE4slk8nw+T5nDgDbwE9gyxryuwpRSF5xz+0BhrT07HA4/AyRJchUYASvAbhiGaRVWLIMBYq3tAojIszkMoNRulbXtPM8HwV/sXSQi54HvQRDcO0wfhGGYArvAKjAq2wAgiqJj3vsHpbtur9f7Vi2utLx60LLW2hljEuBJOYu9OI6vAzQajRvAaeBLURSPlsBelA+VhWGYaq3dwaZvbm6+m06noYicE5ErrVbrK3AXqHvvd4bD4Ye5No7jSERGwKr3Pms2m0pr7Rb30DWbTQWYcnFvAieBT7PZbFB1V6vVfpQaU4UtDQetdTCZTC557/eA48BlY8zbRZ1SqrW2tvaxCvtt2iRJ0i9/xb4x5uJRwmNlaaaJ3AfqIvKY/+78Av++6uiSZhYMAAAAAElFTkSuQmCC\" /> na barra de ferramentas.<br>\n",
    "O parâmetro `dataset` identifica os conjuntos de dados. Você pode importar arquivos de dataset com o botão <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAABhWlDQ1BJQ0MgcHJvZmlsZQAAKJF9kT1Iw0AcxV9TtaIVBzuIOASpThb8QhylikWwUNoKrTqYXPohNGlIUlwcBdeCgx+LVQcXZ10dXAVB8APEydFJ0UVK/F9SaBHjwXE/3t173L0DhFqJqWbbGKBqlpGMRcVMdkUMvKID3QhiCOMSM/V4aiENz/F1Dx9f7yI8y/vcn6NHyZkM8InEs0w3LOJ14ulNS+e8TxxiRUkhPiceNeiCxI9cl11+41xwWOCZISOdnCMOEYuFFpZbmBUNlXiKOKyoGuULGZcVzluc1VKFNe7JXxjMacsprtMcRAyLiCMBETIq2EAJFiK0aqSYSNJ+1MM/4PgT5JLJtQFGjnmUoUJy/OB/8LtbMz854SYFo0D7i21/DAOBXaBete3vY9uunwD+Z+BKa/rLNWDmk/RqUwsfAb3bwMV1U5P3gMsdoP9JlwzJkfw0hXweeD+jb8oCfbdA16rbW2Mfpw9AmrpaugEODoGRAmWveby7s7W3f880+vsBocZyukMJsmwAAAAGYktHRAD/AP8A/6C9p5MAAAAJcEhZcwAADdcAAA3XAUIom3gAAAAHdElNRQfkBgsOBy6ASTeXAAAC/0lEQVQ4y5WUT2gcdRTHP29m99B23Uiq6dZisgoWCxVJW0oL9dqLfyhCvGWY2YUBI95MsXgwFISirQcLhS5hfgk5CF3wJIhFI7aHNsL2VFZFik1jS1qkiZKdTTKZ3/MyDWuz0fQLc/m99/vMvDfv+4RMlUrlkKqeAAaBAWAP8DSgwJ/AXRG5rao/WWsvTU5O3qKLBMD3fSMiPluXFZEPoyj67PGAMzw83PeEMABHVT/oGpiamnoAmCcEWhH5tFsgF4bh9oWFhfeKxeJ5a+0JVT0oImWgBPQCKfAQuAvcBq67rltX1b+6ApMkKRcKhe9V9QLwbavV+qRer692Sx4ZGSnEcXw0TdP3gSrQswGYz+d/S5IkVtXTwOlCoZAGQXAfmAdagAvsAErtdnuXiDy6+023l7qNRsMODg5+CawBzwB9wFPA7mx8ns/KL2Tl3xCRz5eWlkabzebahrHxPG+v4zgnc7ncufHx8Z+Hhoa29fT0lNM03Q30ikiqqg+ttX/EcTy3WTvWgdVqtddaOw/kgXvADHBHROZVNRaRvKruUNU+EdkPfGWM+WJTYOaSt1T1LPDS/4zLWWPMaLVaPWytrYvIaBRFl/4F9H2/JCKvGmMu+76/X0QOqGoZKDmOs1NV28AicMsYc97zvFdc1/0hG6kEeNsY83UnsCwivwM3VfU7YEZE7lhr74tIK8tbnJiYWPY8b6/ruleAXR0ftQy8boyZXi85CIIICDYpc2ZgYODY3NzcHmvt1eyvP64lETkeRdE1yZyixWLx5U2c8q4x5mIQBE1g33/0d3FlZeXFR06ZttZesNZejuO4q1NE5CPgWVV9E3ij47wB1IDlJEn+ljAM86urq7+KyAtZTgqsO0VV247jnOnv7/9xbGzMViqVMVX9uANYj6LonfVtU6vVkjRNj6jqGeCXzGrPAQeA10TkuKpOz87ONrayhnIA2Qo7BZwKw3B7kiRloKSqO13Xja21C47jPNgysFO1Wi0GmtmzQap6DWgD24A1Vb3SGf8Hfstmz1CuXEIAAAAASUVORK5CYII=\" /> na barra de ferramentas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "dataset = \"boston\" #@param {type:\"string\"}\n",
    "target = \"medv\" #@param {type:\"feature\", label:\"Atributo alvo\", description:\"Seu modelo será treinado para prever os valores do alvo.\"}\n",
    "\n",
    "# selected features to perform the model\n",
    "filter_type = \"remover\" #@param [\"incluir\",\"remover\"] {type:\"string\",multiple:false,label:\"Modo de seleção das features\",description:\"Se deseja informar quais features deseja incluir no modelo, selecione a opção 'incluir'. Caso deseje informar as features que não devem ser utilizadas, selecione 'remover'. \"}\n",
    "model_features = \"\" #@param {type:\"feature\",multiple:true,label:\"Features para incluir/remover no modelo\",description:\"Seu modelo será feito considerando apenas as features selecionadas. Caso nada seja especificado, todas as features serão utilizadas\"}\n",
    "\n",
    "# features to apply One Hot Encoder\n",
    "one_hot_features = \"\" #@param {type:\"feature\", multiple:true, label:\"Features para fazer codificação one-hot\", description:\"Seu modelo utilizará a codificação one-hot para as features selecionadas. As demais features categóricas serão codificadas utilizando a codificação ordinal.\"}\n",
    "\n",
    "# hyperparameters\n",
    "time_left_for_this_task = 60 #@param {type:\"integer\", label:\"Tempo máximo de busca\", description:\"Limite de tempo (em segundos) para a procura de modelos apropriados.\"}\n",
    "per_run_time_limit = 60 #@param {type:\"integer\", label:\"Tempo máximo para ajuste de modelo\", description:\"Limite de tempo (em segundos), para uma única chamada, para ajuste de um modelo de Machine Learning.\"}\n",
    "ensemble_size = 50 #@param {type:\"integer\", label:\"Ensemble Learning\", description:\"Número de modelos adicionados ao conjunto criado pela seleção do Ensemble das bibliotecas de modelos.\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acesso ao conjunto de dados\n",
    "\n",
    "O conjunto de dados utilizado nesta etapa será o mesmo carregado através da plataforma.<br>\n",
    "O tipo da variável retornada depende do arquivo de origem:\n",
    "- [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) para CSV e compressed CSV: .csv .csv.zip .csv.gz .csv.bz2 .csv.xz\n",
    "- [Binary IO stream](https://docs.python.org/3/library/io.html#binary-i-o) para outros tipos de arquivo: .jpg .wav .zip .h5 .parquet etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(f'/tmp/data/{dataset}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acesso aos metadados do conjunto de dados\n",
    "\n",
    "Utiliza a função `stat_dataset` do [SDK da PlatIAgro](https://platiagro.github.io/sdk/) para carregar metadados. <br>\n",
    "Por exemplo, arquivos CSV possuem `metadata['featuretypes']` para cada coluna no conjunto de dados (ex: categorical, numerical, or datetime)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from platiagro import stat_dataset\n",
    "\n",
    "metadata = stat_dataset(name=dataset)\n",
    "featuretypes = metadata[\"featuretypes\"]\n",
    "\n",
    "columns = df.columns.to_numpy()\n",
    "featuretypes = np.array(featuretypes)\n",
    "target_index = np.argwhere(columns == target)\n",
    "columns = np.delete(columns, target_index)\n",
    "featuretypes = np.delete(featuretypes, target_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remoção de linhas com valores faltantes no atributo alvo\n",
    "\n",
    "Caso haja linhas em que o atributo alvo contenha valores faltantes, é feita a remoção dos casos faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset = [target],inplace=True)\n",
    "y = df[target].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtragem das features \n",
    "\n",
    "Seleciona apenas as features que foram declaradas no parâmetro model_features. Se nenhuma feature for especificada, todo o conjunto de dados será utilizado para a modelagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filter_type == 'incluir':\n",
    "    if len(model_features) >= 1:\n",
    "        columns_index = (np.where(np.isin(columns,model_features)))[0]\n",
    "        columns_index.sort()\n",
    "        columns_to_filter = columns[columns_index]\n",
    "        featuretypes = featuretypes[columns_index]\n",
    "    else:\n",
    "        columns_to_filter = columns\n",
    "else:\n",
    "    if len(model_features) >= 1:\n",
    "        columns_index = (np.where(np.isin(columns,model_features)))[0]\n",
    "        columns_index.sort()\n",
    "        columns_to_filter = np.delete(columns,columns_index)\n",
    "        featuretypes = np.delete(featuretypes,columns_index)\n",
    "    else:\n",
    "        columns_to_filter = columns\n",
    "\n",
    "# keep the features selected\n",
    "df_model = df[columns_to_filter]\n",
    "X = df_model.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide dataset em subconjuntos de treino e teste\n",
    "\n",
    "Subconjunto de treino: amostra de dados usada para treinar o modelo.<br>\n",
    "Subconjunto de teste: amostra de dados usada para fornecer uma avaliação imparcial do treinamento do modelo no subconjunto de dados de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuração das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro.featuretypes import NUMERICAL\n",
    "\n",
    "# Selects the indexes of numerical and non-numerical features\n",
    "numerical_indexes = np.where(featuretypes == NUMERICAL)[0]\n",
    "non_numerical_indexes = np.where(~(featuretypes == NUMERICAL))[0]\n",
    "\n",
    "\n",
    "# Selects non-numerical features to apply ordinal encoder or one-hot encoder\n",
    "one_hot_features = np.asarray(one_hot_features)\n",
    "non_numerical_indexes_one_hot = np.where(~(featuretypes == NUMERICAL) & np.isin(columns_to_filter,one_hot_features))[0]\n",
    "non_numerical_indexes_ordinal = np.where(~(featuretypes == NUMERICAL) & ~(np.isin(columns_to_filter,one_hot_features)))[0]\n",
    "\n",
    "\n",
    "# After the step handle_missing_values, \n",
    "# numerical features are grouped in the beggining of the array\n",
    "numerical_indexes_after_handle_missing_values = \\\n",
    "    np.arange(len(numerical_indexes))\n",
    "non_numerical_indexes_after_handle_missing_values = \\\n",
    "    np.arange(len(numerical_indexes), len(featuretypes))\n",
    "one_hot_indexes_after_handle_missing_values = non_numerical_indexes_after_handle_missing_values[np.where(np.isin(non_numerical_indexes,non_numerical_indexes_one_hot))[0]]         \n",
    "ordinal_indexes_after_handle_missing_values = non_numerical_indexes_after_handle_missing_values[np.where(np.isin(non_numerical_indexes,non_numerical_indexes_ordinal))[0]]                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treina um modelo usando autosklearn.regression.AutoSklearnRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "from category_encoders.one_hot import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from autosklearn.regression import AutoSklearnRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('handle missing values',\n",
    "     ColumnTransformer(\n",
    "         [('imputer_mean', SimpleImputer(strategy='mean'), numerical_indexes),\n",
    "          ('imputer_mode', SimpleImputer(strategy='most_frequent'), non_numerical_indexes)],\n",
    "         remainder='drop')),\n",
    "    ('handle categorical features',\n",
    "    ColumnTransformer(\n",
    "         [('feature_encoder_ordinal', OrdinalEncoder(), ordinal_indexes_after_handle_missing_values),\n",
    "          ('feature_encoder_onehot', OneHotEncoder(), one_hot_indexes_after_handle_missing_values)],\n",
    "         remainder='passthrough')),\n",
    "    ('estimator', AutoSklearnRegressor(time_left_for_this_task=time_left_for_this_task,\n",
    "                                       per_run_time_limit=per_run_time_limit,\n",
    "                                       ensemble_size=ensemble_size)),\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "X_train = Pipeline(pipeline.steps[:-1]).transform(X_train)\n",
    "pipeline.named_steps.estimator.refit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação de desempenho\n",
    "\n",
    "O [Coeficiente de determinação](https://pt.wikipedia.org/wiki/Coeficiente_de_determinação) (ou R²), corresponde à correlação ao quadrado entre os valores de resultado observados e os valores previstos pelo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# uses the model to make predictions on the Test Dataset\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# computes R²\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva métricas\n",
    "\n",
    "Utiliza a função `save_metrics` do [SDK da PlatIAgro](https://platiagro.github.io/sdk/) para salvar métricas. Por exemplo: `accuracy`, `precision`, `r2_score`, `custom_score` etc.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_metrics\n",
    "\n",
    "save_metrics(r2_score=r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva figuras\n",
    "\n",
    "Utiliza a função `save_figures` do [SDK da PlatIAgro](https://platiagro.github.io/sdk/) para salvar figuras do [matplotlib](https://matplotlib.org/3.2.1/gallery/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from platiagro import save_figure\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "def annotate_plot(e, s, plt, y_lim, h, abs_err):\n",
    "    if h < 2:\n",
    "        p = 0.05\n",
    "    else:\n",
    "        p = 0.1\n",
    "    plt.annotate(\"\", xy=(max(e), y_lim[1]/h),\n",
    "                 xytext=(0, y_lim[1]/h),\n",
    "                 arrowprops=dict(arrowstyle=\"->\"))\n",
    "    plt.annotate(\"\", xy=(min(e), y_lim[1]/h),\n",
    "                 xytext=(0, y_lim[1]/h),\n",
    "                 arrowprops=dict(arrowstyle=\"->\"))\n",
    "    plt.annotate(\"{}%\".format(s),\n",
    "                 xy=(0, (1+p)*y_lim[1]/h),\n",
    "                 ha=\"center\")\n",
    "    if abs_err:\n",
    "        plt.annotate(\"{:.2f}\".format(max(e)),\n",
    "                     xy=((0+max(e))/2, (1-p)*y_lim[1]/h),\n",
    "                     ha=\"center\")\n",
    "        plt.annotate(\"{:.2f}\".format(min(e)),\n",
    "                     xy=((0+min(e))/2, (1-p)*y_lim[1]/h),\n",
    "                     ha=\"center\")\n",
    "    else:\n",
    "        plt.annotate(\"{:.2f}%\".format(100*max(e)),\n",
    "                     xy=((0+max(e))/2, (1-p)*y_lim[1]/h),\n",
    "                     ha=\"center\")\n",
    "        plt.annotate(\"{:.2f}%\".format(100*min(e)),\n",
    "                     xy=((0+min(e))/2, (1-p)*y_lim[1]/h),\n",
    "                     ha=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_err = False\n",
    "if any(y_test==0):\n",
    "    err = y_pred - y_test\n",
    "    abs_err = True\n",
    "else:\n",
    "    err = (y_pred - y_test)/y_test\n",
    "\n",
    "sorted_idx = np.argsort(np.abs(err))\n",
    "n = int(0.7*len(y_test))\n",
    "idx = sorted_idx[:n]\n",
    "e = err[idx]\n",
    "\n",
    "n = int(0.95*len(y_test))\n",
    "idx = sorted_idx[:n]\n",
    "aux = err[idx]\n",
    "x_lim = (aux.min(), aux.max())\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "kde = gaussian_kde(err)\n",
    "x_err = np.linspace(err.min(), err.max(), 1000)\n",
    "p_err = kde(x_err)\n",
    "plt.plot(x_err, p_err, 'b-')\n",
    "\n",
    "y_lim = plt.ylim()\n",
    "plt.ylim((0, y_lim[1]))\n",
    "y_lim = plt.ylim()\n",
    "plt.xlim(x_lim)\n",
    "plt.plot([e.min(), e.min()], y_lim, \"r--\")\n",
    "plt.plot([e.max(), e.max()], y_lim, \"r--\")\n",
    "\n",
    "# Shade the area between e.min() and e.max()\n",
    "plt.fill_betweenx(y_lim, e.min(), e.max(),\n",
    "                  facecolor=\"red\",  # The fill color\n",
    "                  color=\"red\",      # The outline color\n",
    "                  alpha=0.2)        # Transparency of the fill\n",
    "\n",
    "annotate_plot(e, 70, plt, y_lim, 2, abs_err)\n",
    "annotate_plot(aux, 95, plt, y_lim, 1.2, abs_err)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.title(\"Error Distribution\")\n",
    "\n",
    "save_figure(figure=plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva alterações no conjunto de dados\n",
    "\n",
    "O conjunto de dados será salvo (e sobrescrito com as respectivas mudanças) localmente, no container da experimentação, utilizando a função `pandas.DataFrame.to_csv`.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X, y)\n",
    "\n",
    "y_pred = pipeline.predict(X)\n",
    "new_columns = 'AutoMLRegressor'+ '_prediction' \n",
    "df[new_columns] = y_pred\n",
    "\n",
    "# save dataset changes\n",
    "df.to_csv(f'/tmp/data/{dataset}', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva modelo e outros artefatos\n",
    "\n",
    "Utiliza a função `save_model` do [SDK da PlatIAgro](https://platiagro.github.io/sdk/) para salvar modelos e outros artefatos.<br>\n",
    "Essa função torna estes artefatos disponíveis para o notebook de implantação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_model\n",
    "\n",
    "save_model(pipeline=pipeline,\n",
    "           columns=columns,\n",
    "           new_columns=new_columns)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "experiment_id": "6db0fff7-ba9d-4f64-8cbe-9a31bd8b3644",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "operator_id": "1fbe7220-0b4b-4eb6-aba2-b8afec49250d"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
