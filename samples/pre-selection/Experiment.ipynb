{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Selection - Experiment\n",
    "\n",
    "Remove features according to the following criteria:\n",
    "- Variability close to 0\n",
    "- High correlation between each other\n",
    "- Handle NaN and missing values \n",
    "\n",
    "This notebook shows:\n",
    "- how to use the [SDK](https://platiagro.github.io/sdk/) to load datasets, save models and other artifacts.\n",
    "- how to declare parameters and use them to build reusable components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare parameters\n",
    "Components may declare (and use) these default parameters:\n",
    "- dataset\n",
    "- target\n",
    "\n",
    "Use these parameters to load/save datasets, models, metrics, and figures with the help of [PlatIAgro SDK](https://platiagro.github.io/sdk/). <br />\n",
    "You may also declare custom parameters to set when running an experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = \"iris\" #@param {type:\"string\"}\n",
    "target = \"Species\" #@param {type:\"feature\", label:\"Atributo alvo\", description: \"Seu modelo será treinado para prever os valores do alvo.\"}\n",
    "cutoff = 0.9 #@param {type:\"number\", label:\"Limiar de correlação\", description:\"Atributos com correlação maior que o limiar serão removidos.\"}\n",
    "threshold = 0.0 #@param {type:\"number\", label:\"Limiar de threshold\", description:\"Atributos com variância menor que o limiar serão removidos.\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "Import and put the whole dataset in a pandas.DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import load_dataset\n",
    "\n",
    "df = load_dataset(name=dataset)\n",
    "X = df.drop(target, axis=1).to_numpy()\n",
    "y = df[target].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load metadata about the dataset\n",
    "For example, below we get the feature type for each column in the dataset. (eg. categorical, numerical, or datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from platiagro import stat_dataset\n",
    "\n",
    "metadata = stat_dataset(name=dataset)\n",
    "featuretypes = metadata[\"featuretypes\"]\n",
    "\n",
    "columns = df.columns.to_numpy()\n",
    "featuretypes = np.array(featuretypes)\n",
    "target_index = np.argwhere(columns == target)\n",
    "columns = np.delete(columns, target_index)\n",
    "featuretypes = np.delete(featuretypes, target_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping custom transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile CustomTransformer.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class Correlation(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Feature selector that removes correlated features.\n",
    "    \n",
    "    This feature selection algorithm looks only at features(X) and \n",
    "    and removes those with high correlation.\n",
    "    \n",
    "    Attributes:\n",
    "        categorical_indexes: a np.ndarray of categoricals indexes.\n",
    "        cutoff: float of cutoff.\n",
    "        drop_indexes: list of indexes to be droped.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, categorical_indexes: np.ndarray, cutoff: float):\n",
    "        \"\"\"Inits Correlation class.\n",
    "        \n",
    "        Args:\n",
    "            categorical_indexes: categorical indexes of X.\n",
    "            cutoff: cutoff value.\n",
    "        \"\"\"\n",
    "        self.categorical_indexes = categorical_indexes\n",
    "        self.cutoff = cutoff\n",
    "    \n",
    "    def transform(self, X) -> np.ndarray:\n",
    "        \"\"\"Reduce X to the selected features.\n",
    "        \n",
    "        Args:\n",
    "            X: the input samples.\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: the input samples without only the selected features.\n",
    "        \"\"\"\n",
    "        return np.delete(X, np.unique(self.drop_indexes), axis=1)\n",
    "    \n",
    "    def get_support(self) -> np.ndarray:\n",
    "        \"\"\"Returns a list of indexes to be removed.\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: indexes removed by the model.\n",
    "        \"\"\"\n",
    "        return np.unique(self.drop_indexes)\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y=None) -> np.ndarray:\n",
    "        \"\"\"Fit the model.\n",
    "        \n",
    "        Learn correlated features from X.\n",
    "        \n",
    "        Args:\n",
    "            X: the imput sample.\n",
    "        \n",
    "        Returns:\n",
    "            self\n",
    "        \"\"\"\n",
    "        # get only numerical values from X\n",
    "        X_numerical = np.delete(X, self.categorical_indexes, axis=1)\n",
    "        \n",
    "        # check the shape of input\n",
    "        if np.ma.size(X_numerical, axis=0) <= 1 \\\n",
    "        or np.ma.size(X_numerical, axis=1) <= 1:\n",
    "            return X\n",
    "        \n",
    "        # correlation matrix\n",
    "        corr_matrix = np.abs(np.corrcoef(X_numerical.astype(float), rowvar=False))\n",
    "        \n",
    "        # mean correlation for each column\n",
    "        mean_corr = np.mean(corr_matrix, axis=1)\n",
    "\n",
    "        # pairwise correlations above cutoff\n",
    "        above_cutoff = np.argwhere(np.triu(corr_matrix, k=1) > self.cutoff)\n",
    "\n",
    "        # for each pairwise correlation above cutoff\n",
    "        # remove the feature with the highest mean correlation \n",
    "        self.drop_indexes = [\n",
    "            above_cutoff[i, np.argmax(pair)] \n",
    "            for i, pair in enumerate(mean_corr[above_cutoff])]\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro.featuretypes import NUMERICAL\n",
    "\n",
    "# Selects the indexes of numerical and non-numerical features\n",
    "numerical_indexes = np.where(featuretypes == NUMERICAL)[0]\n",
    "non_numerical_indexes = np.where(~(featuretypes == NUMERICAL))[0]\n",
    "\n",
    "# After the step handle_missing_values, \n",
    "# numerical features are grouped in the beggining of the array\n",
    "numerical_indexes_after_handle_missing_values = \\\n",
    "    np.arange(len(numerical_indexes))\n",
    "non_numerical_indexes_after_handle_missing_values = \\\n",
    "    np.arange(len(numerical_indexes), len(featuretypes))\n",
    "\n",
    "# Get non numerical indexes columns names\n",
    "non_numerical_columns = np.take(columns, non_numerical_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove features with low-variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from CustomTransformer import Correlation\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('handle_missing_values', \n",
    "     make_column_transformer((SimpleImputer(strategy='mean'), numerical_indexes),\n",
    "                             (SimpleImputer(strategy='most_frequent'), non_numerical_indexes),\n",
    "                             remainder='drop')),\n",
    "    ('handle_low_variance',\n",
    "     make_column_transformer((VarianceThreshold(threshold=threshold),\n",
    "                              numerical_indexes_after_handle_missing_values),\n",
    "                             remainder='passthrough')),\n",
    "    ('handle_correlated_features',\n",
    "     Correlation(categorical_indexes=non_numerical_indexes_after_handle_missing_values,\n",
    "                 cutoff=cutoff))\n",
    "])\n",
    "\n",
    "# Train model and transform dataset \n",
    "X = pipeline.fit_transform(X)\n",
    "\n",
    "# Get columns name that was not removed by VarianceThreshold\n",
    "remainder_numerical_indexes = \\\n",
    "    np.take(columns, \n",
    "              numerical_indexes[\n",
    "                  pipeline.named_steps.handle_low_variance.named_transformers_.variancethreshold.get_support()])\n",
    "\n",
    "# Removes highly correlated features from the features selected by VarianceThreshold\n",
    "remainder_numerical_indexes = \\\n",
    "    np.delete(remainder_numerical_indexes,\n",
    "              pipeline.named_steps.handle_correlated_features.get_support())\n",
    "\n",
    "# The pipeline changes features order, and it's necessary to save the changes for inference step.\n",
    "# numerical features are in the beggining, and non numerical in the end\n",
    "features_after_pipeline = np.concatenate((remainder_numerical_indexes,\n",
    "                                          non_numerical_columns))\n",
    "\n",
    "# Convert back to DataFrame\n",
    "df = pd.DataFrame(X, columns=features_after_pipeline)\n",
    "df[target] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataset\n",
    "\n",
    "Stores the transformed dataset in a object storage.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_dataset\n",
    "\n",
    "save_dataset(name=dataset, df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model\n",
    "\n",
    "Stores the model artifacts in a object storage.<br>\n",
    "It will make the model available for future deployments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_model\n",
    "\n",
    "save_model(pipeline=pipeline,\n",
    "           columns=columns,\n",
    "           features_after_pipeline=features_after_pipeline)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "experiment_id": "94c3e6b9-0420-4d48-a5df-2d31fc2ad3af",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "operator_id": "a43611a0-3d85-4bee-b94a-4ab7b01e9e21"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
