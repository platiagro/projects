{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Selection\n",
    "\n",
    "Remove features according to the following criteria:\n",
    "- Variability close to 0\n",
    "- High correlation between each other\n",
    "- Handle NaN and missing values \n",
    "\n",
    "This notebook shows:\n",
    "- how to use the [SDK](https://platiagro.github.io/sdk/) to load datasets, save models and other artifacts.\n",
    "- how to declare parameters and use them to build reusable components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare parameters\n",
    "Components may declare (and use) these default parameters:\n",
    "- dataset\n",
    "- target\n",
    "\n",
    "Use these parameters to load/save datasets, models, metrics, and figures with the help of [PlatIAgro SDK](https://platiagro.github.io/sdk/). <br />\n",
    "You may also declare custom parameters to set when running an experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = \"iris\" #@param {type:\"string\"}\n",
    "target = \"Species\" #@param {type:\"string\"}\n",
    "correlation = 0.95 #@param {type:\"number\", label:\"Correlação\", description:\"Valor para o corte de correlação entre features\"}\n",
    "threshold = 0.0 #@param {type:\"number\", label:\"Limiar\", description:\"Atributos com variância menor que o limiar serão removidos\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "Import and put the whole dataset in a pandas.DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import load_dataset\n",
    "\n",
    "df = load_dataset(name=dataset)\n",
    "X = df.drop(target, axis=1).to_numpy()\n",
    "y = df[target].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load metadata about the dataset\n",
    "For example, below we get the feature type for each column in the dataset. (eg. categorical, numerical, or datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from platiagro import stat_dataset\n",
    "\n",
    "metadata = stat_dataset(name=dataset)\n",
    "featuretypes = metadata[\"featuretypes\"]\n",
    "\n",
    "columns = df.columns.to_numpy()\n",
    "featuretypes = np.array(featuretypes)\n",
    "target_index = np.argwhere(columns == target)\n",
    "columns = np.delete(columns, target_index)\n",
    "featuretypes = np.delete(featuretypes, target_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping custom transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile CustomTransformer.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CorrelatedFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, c_indexes, correlation):\n",
    "        self.categorical_indexes = c_indexes\n",
    "        self.correlation = correlation\n",
    "    \n",
    "    def fit(self, X=None):\n",
    "        return self\n",
    "    \n",
    "    def get_support(self):\n",
    "        \"\"\"Returns indexes to be removed\"\"\"\n",
    "        return self._drop_indexes\n",
    "    \n",
    "    def transform(self, input_series):\n",
    "        \"\"\"Transform data\"\"\"\n",
    "        # Select only numerical features from input\n",
    "        X_n = pd.DataFrame(np.delete(input_series, self.categorical_indexes, axis=1))\n",
    "\n",
    "        # Create correlation matrix\n",
    "        corr_matrix = X_n.corr().abs()\n",
    "\n",
    "        # Select upper triangle of correlation matrix\n",
    "        upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "        # Find features with correlation greater than correlation predefined\n",
    "        self._drop_indexes = [column for column in upper_triangle.columns if any(upper_triangle[column] > self.correlation)]\n",
    "\n",
    "        # Drop features\n",
    "        X_n.drop(X_n.columns[self._drop_indexes], axis=1, inplace=True)\n",
    "\n",
    "        # Put every numerical feature on first indexes and make new series of it\n",
    "        new_series = np.concatenate((X_n, input_series[:, self.categorical_indexes]), axis=1)\n",
    "\n",
    "        return new_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro.featuretypes import NUMERICAL\n",
    "\n",
    "# Selects the indexes of numerical and non-numerical features\n",
    "numerical_indexes = np.where(featuretypes == NUMERICAL)[0]\n",
    "non_numerical_indexes = np.where(~(featuretypes == NUMERICAL))[0]\n",
    "\n",
    "# After the step handle_missing_values, \n",
    "# numerical features are grouped in the beggining of the array\n",
    "numerical_indexes_after_handle_missing_values = \\\n",
    "    np.arange(len(numerical_indexes))\n",
    "non_numerical_indexes_after_handle_missing_values = \\\n",
    "    np.arange(len(numerical_indexes), len(featuretypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove features with low-variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from CustomTransformer import CorrelatedFeatures\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('handle_missing_values', \n",
    "     ColumnTransformer(\n",
    "        [('imputer_mean', SimpleImputer(strategy='mean'), numerical_indexes),\n",
    "         ('imputer_mode', SimpleImputer(strategy='most_frequent'), non_numerical_indexes)],\n",
    "         remainder='drop')),\n",
    "    ('handle_low_variance',\n",
    "     ColumnTransformer(\n",
    "         [('variance_threshold', VarianceThreshold(threshold=threshold),\n",
    "           numerical_indexes_after_handle_missing_values)],\n",
    "          remainder='passthrough')),\n",
    "    ('correlated_features',\n",
    "     CorrelatedFeatures(c_indexes=non_numerical_indexes_after_handle_missing_values,\n",
    "                        correlation=correlation))\n",
    "])\n",
    "\n",
    "X_n = pipeline.fit_transform(X)\n",
    "\n",
    "# Get features selected by VarianceThreshold\n",
    "threshold_features = \\\n",
    "pipeline.named_steps.handle_low_variance.named_transformers_.variance_threshold.get_support()\n",
    "\n",
    "# Removes highly correlated features from the features selected by VarianceThreshold\n",
    "numerical_indexes = \\\n",
    "np.delete(numerical_indexes[threshold_features], pipeline.named_steps.correlated_features.get_support())\n",
    "\n",
    "# The pipeline changes features order, and it's necessary to save the changes for inference step.\n",
    "# numerical features are in the beggining, and non numerical in the end\n",
    "features_after_pipeline = \\\n",
    "columns[np.concatenate([numerical_indexes, non_numerical_indexes])]\n",
    "\n",
    "# Convert back to DataFrame\n",
    "df = pd.DataFrame(X_n, columns=features_after_pipeline)\n",
    "df[target] = pd.Series(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataset\n",
    "\n",
    "Stores the transformed dataset in a object storage.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_dataset\n",
    "\n",
    "save_dataset(name=dataset, df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model\n",
    "\n",
    "Stores the model artifacts in a object storage.<br>\n",
    "It will make the model available for future deployments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_model\n",
    "\n",
    "save_model(pipeline=pipeline,\n",
    "           columns=columns)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "experiment_id": "94c3e6b9-0420-4d48-a5df-2d31fc2ad3af",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "operator_id": "a43611a0-3d85-4bee-b94a-4ab7b01e9e21"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
