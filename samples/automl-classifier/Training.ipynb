{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML Classifier\n",
    "\n",
    "This is a component that trains an AutoML Classifier model using [auto-sklearn](https://github.com/automl/auto-sklearn). \n",
    "<br>\n",
    "auto-sklearn is an automated machine learning toolkit and a drop-in replacement for a scikit-learn estimator.\n",
    "\n",
    "This notebook shows:\n",
    "- how to use SDK to load the dataset and save a model.\n",
    "- how to receive parameters from the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = \"iris\" #@param {type:\"string\"}\n",
    "target = \"Species\" #@param {type:\"string\"}\n",
    "experiment_id = \"48f2668a-e31a-4b5a-a91a-28fd649f7adc\" #@param {type:\"string\"}\n",
    "operator_id = \"64401802-2785-4f26-85c8-d7974fc78454\" #@param {type:\"string\"}\n",
    "duration = 60 #@param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "Import and put the whole dataset in a pandas.DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import load_dataset\n",
    "\n",
    "df = load_dataset(name=dataset)\n",
    "X = df.drop(target, axis=1).to_numpy()\n",
    "y = df[target].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load metadata\n",
    "In this context, metadata means information about the dataset.<br>\n",
    "For example, below we get the feature type for each column in the dataset. (eg. categorical, numerical, or datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import load_metadata\n",
    "from platiagro.featuretypes import infer_featuretypes\n",
    "\n",
    "try:\n",
    "    metadata = load_metadata(name=dataset)\n",
    "    featuretypes = metadata[\"featuretypes\"]\n",
    "except KeyError:\n",
    "    featuretypes = infer_featuretypes(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorical features\n",
    "\n",
    "Many machine learning algorithms cannot operate on categorical data directly. They require all input variables and output variables to be numeric.<br>\n",
    "This means that categorical data must be converted to a numerical form.<br>\n",
    "The features are converted to ordinal integers. This results in a single column of integers (0 to n_categories - 1) per feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro.featuretypes import CATEGORICAL\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "target_idx = df.columns.tolist().index(target)\n",
    "# selects the categorical features\n",
    "categorical_idxs = [idx for idx, ft in enumerate(featuretypes) if ft == CATEGORICAL and idx != target_idx]\n",
    "feature_encoder = OrdinalEncoder()\n",
    "\n",
    "if len(categorical_idxs) > 0:\n",
    "    X[:, categorical_idxs] = feature_encoder.fit_transform(X[:, categorical_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode target labels\n",
    "\n",
    "The target labels are converted to ordinal integers with value between 0 and n_classes-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into train/test splits\n",
    "\n",
    "Training Dataset: the sample of data used to fit the model.\n",
    "\n",
    "Test Dataset: the sample of data used to provide an unbiased evaluation of a model fit on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a model using autosklearn.classification.AutoSklearnClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autosklearn.classification import AutoSklearnClassifier\n",
    "\n",
    "# removes target column from 'featuretypes'\n",
    "index = df.columns.tolist().index(target)\n",
    "featuretypes.pop(index)\n",
    "\n",
    "estimator = AutoSklearnClassifier(\n",
    "    time_left_for_this_task=duration,\n",
    "    per_run_time_limit=duration,\n",
    ")\n",
    "estimator.fit(X_train, y_train, feat_type=featuretypes)\n",
    "estimator.refit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure the performance\n",
    "The [**Confusion Matrix**](https://en.wikipedia.org/wiki/Confusion_matrix) is a performance measurement for machine learning classification.<br>\n",
    "It is extremely useful for measuring [Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification), [Recall, Precision, and F-measure](https://en.wikipedia.org/wiki/Precision_and_recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# uses the model to make predictions on the Test Dataset\n",
    "y_pred = estimator.predict(X_test)\n",
    "\n",
    "# computes confusion matrix\n",
    "labels = np.unique(y)\n",
    "data = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "\n",
    "# puts matrix in pandas.DataFrame for better format\n",
    "labels = label_encoder.inverse_transform(labels)\n",
    "confusion_matrix = pd.DataFrame(data, columns=labels, index=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save metrics\n",
    "\n",
    "Record the metrics used to evaluate the model.<br>\n",
    "It's a good way to document the experiments, and also help to avoid running the same experiment twice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_metrics\n",
    "\n",
    "save_metrics(experiment_id=experiment_id, operator_id=operator_id, confusion_matrix=confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model\n",
    "\n",
    "Stores the model artifacts in a object storage.<br>\n",
    "It will make the model available for future deployments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_model\n",
    "\n",
    "save_model(experiment_id=experiment_id, model={\"estimator\": estimator, \"feature_encoder\": feature_encoder, \"label_encoder\": label_encoder})"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
