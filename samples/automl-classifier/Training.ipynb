{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML Classifier\n",
    "\n",
    "This is a component that trains an AutoML Classifier model using [auto-sklearn](https://github.com/automl/auto-sklearn). \n",
    "<br>\n",
    "auto-sklearn is an automated machine learning toolkit and a drop-in replacement for a scikit-learn estimator.\n",
    "\n",
    "This notebook shows:\n",
    "- how to use the [SDK](https://platiagro.github.io/sdk/) to load datasets, save models and other artifacts.\n",
    "- how to declare parameters and use them to build reusable components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare parameters and model hyperparameters\n",
    "Components may declare (and use) these default parameters:\n",
    "- dataset\n",
    "- target\n",
    "\n",
    "Use these parameters to load/save datasets, models, metrics, and figures with the help of [PlatIAgro SDK](https://platiagro.github.io/sdk/). <br />\n",
    "You may also declare custom parameters to set when running an experiment.\n",
    "\n",
    "Select the hyperparameters and their respective values to be used when training the model:\n",
    "- time_left_for_this_task\n",
    "- per_run_time_limit\n",
    "- ensemble_size\n",
    "\n",
    "These parameters are just a few offered by the model class, you may also use another existing parameter. <br />\n",
    "Check the [model parameters](https://automl.github.io/auto-sklearn/master/api.html#autosklearn.classification.AutoSklearnClassifier) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "dataset = \"iris\" #@param {type:\"string\"}\n",
    "target = \"Species\" #@param {type:\"string\"}\n",
    "\n",
    "# hyperparameters\n",
    "time_left_for_this_task = 60 #@param {type:\"integer\", label:\"Limite de tempo (em segundos)\", description:\"Limite de tempo para a procura de modelos apropriados\"}\n",
    "per_run_time_limit = 60 #@param {type:\"integer\", label:\"Limite de tempo (em segundos)\", description:\"Prazo para uma única chamada para o modelo de Machine Learning\"}\n",
    "ensemble_size = 50 #@param {type:\"integer\", label:\"Ensemble Learning\", description:\"Número de modelos adicionados ao conjunto criado pela seleção do Ensemble das bibliotecas de modelos\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "Import and put the whole dataset in a pandas.DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import load_dataset\n",
    "\n",
    "df = load_dataset(name=dataset)\n",
    "X = df.drop(target, axis=1).to_numpy()\n",
    "y = df[target].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load metadata about the dataset\n",
    "For example, below we get the feature type for each column in the dataset. (eg. categorical, numerical, or datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from platiagro import stat_dataset\n",
    "\n",
    "metadata = stat_dataset(name=dataset)\n",
    "featuretypes = metadata[\"featuretypes\"]\n",
    "\n",
    "columns = df.columns.to_numpy()\n",
    "featuretypes = np.array(featuretypes)\n",
    "target_index = np.argwhere(columns == target)\n",
    "columns = np.delete(columns, target_index)\n",
    "featuretypes = np.delete(featuretypes, target_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode target labels\n",
    "\n",
    "The target labels are converted to ordinal integers with value between 0 and n_classes-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into train/test splits\n",
    "\n",
    "Training Dataset: the sample of data used to fit the model.\n",
    "\n",
    "Test Dataset: the sample of data used to provide an unbiased evaluation of a model fit on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a model using autosklearn.classification.AutoSklearnClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from autosklearn.classification import AutoSklearnClassifier\n",
    "from platiagro.featuretypes import NUMERICAL\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "numerical_indexes = (featuretypes == NUMERICAL)\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('handle missing values', ColumnTransformer(\n",
    "    [('imputer_mean', SimpleImputer(strategy='mean'), numerical_indexes),\n",
    "     ('imputer_mode', SimpleImputer(strategy='most_frequent'), ~numerical_indexes)],\n",
    "    remainder='drop')),\n",
    "    ('handle categorical features', ColumnTransformer(\n",
    "    [('feature_encoder', OrdinalEncoder(), ~numerical_indexes)],\n",
    "    remainder='passthrough')),\n",
    "    ('variance threshold', VarianceThreshold(threshold=0)),\n",
    "    ('estimator', AutoSklearnClassifier(time_left_for_this_task=time_left_for_this_task,\n",
    "                                        per_run_time_limit=per_run_time_limit,\n",
    "                                        ensemble_size=ensemble_size)),\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "pipeline.named_steps.estimator.refit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure the performance\n",
    "The [**Confusion Matrix**](https://en.wikipedia.org/wiki/Confusion_matrix) is a performance measurement for machine learning classification.<br>\n",
    "It is extremely useful for measuring [Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification), [Recall, Precision, and F-measure](https://en.wikipedia.org/wiki/Precision_and_recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# uses the model to make predictions on the Test Dataset\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# computes confusion matrix\n",
    "labels = np.unique(y)\n",
    "data = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "\n",
    "# puts matrix in pandas.DataFrame for better format\n",
    "labels = label_encoder.inverse_transform(labels)\n",
    "confusion_matrix = pd.DataFrame(data, columns=labels, index=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save metrics\n",
    "\n",
    "Record the metrics used to evaluate the model.<br>\n",
    "It's a good way to document the experiments, and also help to avoid running the same experiment twice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_metrics\n",
    "\n",
    "save_metrics(confusion_matrix=confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model\n",
    "\n",
    "Stores the model artifacts in a object storage.<br>\n",
    "It will make the model available for future deployments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platiagro import save_model\n",
    "\n",
    "save_model(pipeline=pipeline,\n",
    "           label_encoder=label_encoder,\n",
    "           columns=columns)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "experiment_id": "48f2668a-e31a-4b5a-a91a-28fd649f7adc",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "operator_id": "64401802-2785-4f26-85c8-d7974fc78454"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
