{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML Classifier\n",
    "\n",
    "This is a component that performs predictions using an AutoML Classifier implementation from [autosklearn](https://github.com/automl/auto-sklearn). \n",
    "<br>\n",
    "auto-sklearn is an automated machine learning toolkit and a drop-in replacement for a scikit-learn estimator.\n",
    "\n",
    "This notebook shows:\n",
    "- how to use the [SDK](https://platiagro.github.io/sdk/) to load a model and other artifacts.\n",
    "- how to use a model to provide real-time predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Model.py\n",
    "import logging\n",
    "from typing import List, Iterable, Dict, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from platiagro import load_model\n",
    "from platiagro.featuretypes import CATEGORICAL, NUMERICAL, infer_featuretypes\n",
    "from sklearn.exceptions import NotFittedError \n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class Model(object):\n",
    "    def __init__(self, dataset: str = None, target: str = None, experiment_id: str = None, method: str = \"predict_proba\"):\n",
    "        logger.info(f\"dataset: {dataset}\")\n",
    "        logger.info(f\"target: {target}\")\n",
    "        logger.info(f\"experiment_id: {experiment_id}\")\n",
    "        logger.info(f\"method: {method}\")\n",
    "\n",
    "        self.method = method\n",
    "\n",
    "        # Load Artifacts: Estimator, Encoders, etc\n",
    "        model = load_model(experiment_id=experiment_id)\n",
    "        self.estimator = model[\"estimator\"]\n",
    "        self.feature_encoder = model[\"feature_encoder\"]\n",
    "        self.label_encoder = model[\"label_encoder\"]\n",
    "        self.columns = model[\"columns\"]\n",
    "        self.datetime_indexes = model[\"datetime_indexes\"]\n",
    "        self.categorical_indexes = model[\"categorical_indexes\"]\n",
    "        self.numerical_nan_replacement = model[\"numerical_nan_replacement\"]\n",
    "        self.categorical_nan_replacement = model[\"categorical_nan_replacement\"]\n",
    "\n",
    "    def class_names(self):\n",
    "        if self.method == \"predict_proba\":\n",
    "            return self.label_encoder.classes_.tolist()\n",
    "        else:\n",
    "            return [\"class\"]\n",
    "\n",
    "    def predict(self, X: np.ndarray, feature_names: Iterable[str], meta: Dict = None) -> Union[np.ndarray, List, str, bytes]:\n",
    "        \"\"\"Takes an array (numpy) X and feature_names and returns an array of predictions.\n",
    "\n",
    "        Args:\n",
    "            X (numpy.array): Array-like with data.\n",
    "            feature_names (iterable, optional): Array of feature names.\n",
    "            meta (dict, optional): Dict of metadata.\n",
    "        \"\"\"\n",
    "        # Put data in a pandas.DataFrame\n",
    "        df = pd.DataFrame(X, columns=feature_names)\n",
    "\n",
    "        # Replace NaNs\n",
    "        df.fillna(self.categorical_nan_replacement, inplace=True)\n",
    "        df.fillna(self.numerical_nan_replacement, inplace=True)\n",
    "\n",
    "        # Put data back in a numpy.ndarray\n",
    "        X = df[self.columns].to_numpy()\n",
    "\n",
    "        # Remove datetime features\n",
    "        X = X[:, np.where(~self.datetime_indexes)[0]]\n",
    "\n",
    "        # Encode categorical features\n",
    "        if np.ma.any(self.categorical_indexes):\n",
    "            X[:, self.categorical_indexes] = \\\n",
    "                self.feature_encoder.transform(X[:, self.categorical_indexes])\n",
    "\n",
    "        # Perform Prediction\n",
    "        if self.method == \"predict_proba\":\n",
    "            y_pred = self.estimator.predict_proba(X)\n",
    "        else:\n",
    "            y_pred = self.estimator.predict(X)\n",
    "            y_pred = self.label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment Test\n",
    "\n",
    "It simulates a model deployed by PlatIAgro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile env.sh\n",
    "export MODEL_NAME=\"Model\"\n",
    "export API_TYPE=\"REST\"\n",
    "export SERVICE_TYPE=\"MODEL\"\n",
    "export PERSISTENCE=0\n",
    "export LOG_LEVEL=\"DEBUG\"\n",
    "export PARAMETERS='[\n",
    "{\"type\":\"STRING\",\"name\":\"dataset\",\"value\":\"iris\"},\n",
    "{\"type\":\"STRING\",\"name\":\"target\",\"value\":\"Species\"},\n",
    "{\"type\":\"STRING\",\"name\":\"experiment_id\",\"value\":\"48f2668a-e31a-4b5a-a91a-28fd649f7adc\"}]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source env.sh\n",
    "seldon-core-microservice \"$MODEL_NAME\" \"$API_TYPE\" \\\n",
    "    --service-type \"$SERVICE_TYPE\" \\\n",
    "    --persistence \"$PERSISTENCE\" \\\n",
    "    --parameters \"$PARAMETERS\" \\\n",
    "    --log-level \"$LOG_LEVEL\" > log.txt 2>&1 &\n",
    "\n",
    "ATTEMPT=0\n",
    "until $(curl --output /dev/null --silent --head --fail http://localhost:5000/health/ping); do\n",
    "    # exit process if not healthy after 10 seconds\n",
    "    if [ \"$ATTEMPT\" -gt 10 ]; then\n",
    "        cat log.txt\n",
    "        exit 1\n",
    "    fi\n",
    "    ATTEMPT=$((ATTEMPT + 1))\n",
    "    sleep 1\n",
    "done\n",
    "echo \"Deployment successful. Waiting for requests.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl -sSL localhost:5000/predict --data-binary @- << EOF\n",
    "json={\n",
    "    \"data\": {\n",
    "        \"names\": [\"SepalLengthCm\",\"SepalWidthCm\",\"PetalLengthCm\",\"PetalWidthCm\"],\n",
    "        \"ndarray\": [\n",
    "            [5.1,3.5,1.4,0.2]\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleans up the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ps -ef | grep [s]eldon-core-mic | awk '{print $2}' | xargs -r kill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}